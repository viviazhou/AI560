{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1939674-be5c-4856-9c53-2b3a0173da42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 1: DOWNLOADING GOOGLE FONTS\n",
      "============================================================\n",
      "\n",
      "üì¶ Installing required packages...\n",
      "Requirement already satisfied: fonttools in /opt/conda/lib/python3.12/site-packages (4.58.5)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: pillow in /opt/conda/lib/python3.12/site-packages (11.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests) (2024.7.4)\n",
      "\n",
      "üìÅ Creating directories...\n",
      "\n",
      "üì• Cloning Google Fonts repository...\n",
      "   (This may take 2-3 minutes - it's ~500MB)\n",
      "Cloning into 'google_fonts_repo'...\n",
      "remote: Enumerating objects: 18985, done.\u001b[K\n",
      "remote: Counting objects: 100% (18985/18985), done.\u001b[K\n",
      "remote: Compressing objects: 100% (15371/15371), done.\u001b[K\n",
      "remote: Total 18985 (delta 3909), reused 12827 (delta 3050), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (18985/18985), 1.18 GiB | 14.30 MiB/s, done.\n",
      "Resolving deltas: 100% (3909/3909), done.\n",
      "Checking connectivity: 18985, done.\n",
      "Updating files: 100% (16945/16945), done.\n",
      "\n",
      "‚úÖ Google Fonts repository downloaded!\n",
      "\n",
      "üìä Analyzing downloaded fonts...\n",
      "\n",
      "   Total .ttf files found: 3817\n",
      "   Regular fonts: 3083\n",
      "   Variable fonts: 734\n",
      "   Unique font families: 1448\n",
      "\n",
      "üìù Sample fonts:\n",
      "   ‚Ä¢ Aclonica-Regular.ttf\n",
      "   ‚Ä¢ Calligraffitti-Regular.ttf\n",
      "   ‚Ä¢ CherryCreamSoda-Regular.ttf\n",
      "   ‚Ä¢ Chewy-Regular.ttf\n",
      "   ‚Ä¢ ComingSoon-Regular.ttf\n",
      "   ‚Ä¢ Cousine-Bold.ttf\n",
      "   ‚Ä¢ Cousine-BoldItalic.ttf\n",
      "   ‚Ä¢ Cousine-Italic.ttf\n",
      "   ‚Ä¢ Cousine-Regular.ttf\n",
      "   ‚Ä¢ CraftyGirls-Regular.ttf\n",
      "\n",
      "   ... and 3073 more\n",
      "\n",
      "‚úÖ Step 1 complete! Ready for Step 2 (generating training images)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 1: DOWNLOADING GOOGLE FONTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Install required packages\n",
    "print(\"\\nüì¶ Installing required packages...\")\n",
    "!pip install fonttools requests pillow\n",
    "\n",
    "import os\n",
    "import glob\n",
    "from pathlib import Path\n",
    "\n",
    "# Create directories\n",
    "print(\"\\nüìÅ Creating directories...\")\n",
    "fonts_dir = Path(\"google_fonts_repo\")\n",
    "fonts_dir.mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\nüì• Cloning Google Fonts repository...\")\n",
    "print(\"   (This may take 2-3 minutes - it's ~500MB)\")\n",
    "\n",
    "# Clone the Google Fonts GitHub repo\n",
    "!git clone --depth 1 https://github.com/google/fonts.git google_fonts_repo\n",
    "\n",
    "print(\"\\n‚úÖ Google Fonts repository downloaded!\")\n",
    "\n",
    "# Analyze what we got\n",
    "print(\"\\nüìä Analyzing downloaded fonts...\")\n",
    "\n",
    "# Find all .ttf files\n",
    "font_files = glob.glob(\"google_fonts_repo/**/*.ttf\", recursive=True)\n",
    "print(f\"\\n   Total .ttf files found: {len(font_files)}\")\n",
    "\n",
    "# Separate regular fonts from variable fonts\n",
    "regular_fonts = [f for f in font_files if \"[\" not in f]\n",
    "variable_fonts = [f for f in font_files if \"[\" in f]\n",
    "\n",
    "print(f\"   Regular fonts: {len(regular_fonts)}\")\n",
    "print(f\"   Variable fonts: {len(variable_fonts)}\")\n",
    "\n",
    "# Get unique font families\n",
    "font_families = set()\n",
    "for font_path in regular_fonts:\n",
    "    # Extract font family name from path\n",
    "    parts = Path(font_path).parts\n",
    "    if len(parts) >= 3:\n",
    "        font_families.add(parts[-2])\n",
    "\n",
    "print(f\"   Unique font families: {len(font_families)}\")\n",
    "\n",
    "# Show some examples\n",
    "print(\"\\nüìù Sample fonts:\")\n",
    "for i, font_path in enumerate(regular_fonts[:10]):\n",
    "    font_name = Path(font_path).name\n",
    "    print(f\"   ‚Ä¢ {font_name}\")\n",
    "\n",
    "print(f\"\\n   ... and {len(regular_fonts) - 10} more\")\n",
    "\n",
    "print(\"\\n‚úÖ Step 1 complete! Ready for Step 2 (generating training images)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f29cc27b-ea80-4bf1-8fa2-7b1aea4980af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 2: GENERATING TRAINING IMAGES\n",
      "============================================================\n",
      "üöÄ Starting dataset generation...\n",
      "   Starting with 200 fonts to test (about 2,000 images)\n",
      "   This should take 3-5 minutes...\n",
      "\n",
      "\n",
      "üé® Generating dataset from 200 fonts...\n",
      "   Creating 10 samples per font\n",
      "   Total target: 2000 images\n",
      "\n",
      "   ‚úì Processed 100/200 fonts (1000 images generated)\n",
      "   ‚úì Processed 200/200 fonts (2000 images generated)\n",
      "\n",
      "‚úÖ Dataset generation complete!\n",
      "   Total images generated: 2000\n",
      "   Unique font families: 105\n",
      "   Failed fonts: 0\n",
      "\n",
      "üìä Dataset ready!\n",
      "   Location: training_data/\n",
      "   Ready for Step 3: Model Training\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 2: GENERATING TRAINING IMAGES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import random\n",
    "import json\n",
    "\n",
    "class GoogleFontsDatasetGenerator:\n",
    "    def __init__(self, fonts_dir=\"google_fonts_repo\", output_dir=\"training_data\"):\n",
    "        self.fonts_dir = Path(fonts_dir)\n",
    "        self.output_dir = Path(output_dir)\n",
    "        self.output_dir.mkdir(exist_ok=True)\n",
    "        \n",
    "        # Sample texts to render\n",
    "        self.sample_texts = [\n",
    "            \"The quick brown fox jumps over the lazy dog\",\n",
    "            \"ABCDEFGHIJKLMNOPQRSTUVWXYZ\",\n",
    "            \"abcdefghijklmnopqrstuvwxyz\",\n",
    "            \"0123456789\",\n",
    "            \"Hello World! Design Systems 2025\",\n",
    "            \"Typography & Layout Patterns\",\n",
    "            \"Beautiful Design Tokens\",\n",
    "            \"Color Spacing Grid\",\n",
    "        ]\n",
    "        \n",
    "        # Image settings\n",
    "        self.img_size = (320, 320)\n",
    "        self.font_sizes = [28, 36, 44, 52, 60]\n",
    "        \n",
    "    def get_font_files(self):\n",
    "        \"\"\"Get all .ttf files from Google Fonts repo\"\"\"\n",
    "        font_files = list(self.fonts_dir.glob(\"**/*.ttf\"))\n",
    "        # Filter out variable fonts for now\n",
    "        font_files = [f for f in font_files if \"[\" not in f.name]\n",
    "        return font_files\n",
    "    \n",
    "    def generate_image(self, font_path, text, font_size):\n",
    "        \"\"\"Generate a single training image\"\"\"\n",
    "        try:\n",
    "            # Create white background\n",
    "            img = Image.new('RGB', self.img_size, color='white')\n",
    "            draw = ImageDraw.Draw(img)\n",
    "            \n",
    "            # Load font\n",
    "            font = ImageFont.truetype(str(font_path), font_size)\n",
    "            \n",
    "            # Calculate text position (centered)\n",
    "            bbox = draw.textbbox((0, 0), text, font=font)\n",
    "            text_width = bbox[2] - bbox[0]\n",
    "            text_height = bbox[3] - bbox[1]\n",
    "            \n",
    "            x = (self.img_size[0] - text_width) // 2\n",
    "            y = (self.img_size[1] - text_height) // 2\n",
    "            \n",
    "            # Draw text in black\n",
    "            draw.text((x, y), text, font=font, fill='black')\n",
    "            \n",
    "            return img\n",
    "        except Exception as e:\n",
    "            # Some fonts might fail to load or render\n",
    "            return None\n",
    "    \n",
    "    def generate_dataset(self, samples_per_font=10, max_fonts=None):\n",
    "        \"\"\"Generate full training dataset\"\"\"\n",
    "        font_files = self.get_font_files()\n",
    "        \n",
    "        if max_fonts:\n",
    "            font_files = font_files[:max_fonts]\n",
    "        \n",
    "        print(f\"\\nüé® Generating dataset from {len(font_files)} fonts...\")\n",
    "        print(f\"   Creating {samples_per_font} samples per font\")\n",
    "        print(f\"   Total target: {len(font_files) * samples_per_font} images\\n\")\n",
    "        \n",
    "        dataset_info = []\n",
    "        total_generated = 0\n",
    "        failed_fonts = []\n",
    "        \n",
    "        for font_idx, font_path in enumerate(font_files):\n",
    "            # Get font family name\n",
    "            font_name = font_path.stem  # e.g., \"Roboto-Regular\"\n",
    "            \n",
    "            # Extract family name (the parent directory)\n",
    "            font_family = font_path.parent.name\n",
    "            \n",
    "            # Create directory for this font family\n",
    "            font_output_dir = self.output_dir / font_family\n",
    "            font_output_dir.mkdir(exist_ok=True)\n",
    "            \n",
    "            # Generate multiple samples\n",
    "            samples_generated = 0\n",
    "            for sample_idx in range(samples_per_font):\n",
    "                # Random text and size\n",
    "                text = random.choice(self.sample_texts)\n",
    "                font_size = random.choice(self.font_sizes)\n",
    "                \n",
    "                # Generate image\n",
    "                img = self.generate_image(font_path, text, font_size)\n",
    "                \n",
    "                if img:\n",
    "                    # Save image\n",
    "                    img_filename = f\"{font_name}_{sample_idx}.png\"\n",
    "                    img_path = font_output_dir / img_filename\n",
    "                    img.save(img_path)\n",
    "                    \n",
    "                    # Record metadata\n",
    "                    dataset_info.append({\n",
    "                        'image_path': str(img_path),\n",
    "                        'font_name': font_name,\n",
    "                        'font_family': font_family,\n",
    "                        'text': text,\n",
    "                        'font_size': font_size\n",
    "                    })\n",
    "                    \n",
    "                    total_generated += 1\n",
    "                    samples_generated += 1\n",
    "            \n",
    "            if samples_generated == 0:\n",
    "                failed_fonts.append(str(font_path))\n",
    "            \n",
    "            # Progress update every 100 fonts\n",
    "            if (font_idx + 1) % 100 == 0:\n",
    "                print(f\"   ‚úì Processed {font_idx + 1}/{len(font_files)} fonts ({total_generated} images generated)\")\n",
    "        \n",
    "        print(f\"\\n‚úÖ Dataset generation complete!\")\n",
    "        print(f\"   Total images generated: {total_generated}\")\n",
    "        print(f\"   Unique font families: {len(set(info['font_family'] for info in dataset_info))}\")\n",
    "        print(f\"   Failed fonts: {len(failed_fonts)}\")\n",
    "        \n",
    "        # Save dataset metadata\n",
    "        with open(self.output_dir / \"dataset_info.json\", 'w') as f:\n",
    "            json.dump(dataset_info, f, indent=2)\n",
    "        \n",
    "        if failed_fonts:\n",
    "            with open(self.output_dir / \"failed_fonts.txt\", 'w') as f:\n",
    "                f.write(\"\\n\".join(failed_fonts))\n",
    "        \n",
    "        return dataset_info\n",
    "\n",
    "# Create generator\n",
    "generator = GoogleFontsDatasetGenerator()\n",
    "\n",
    "# Generate dataset - starting with 200 fonts for testing\n",
    "print(\"üöÄ Starting dataset generation...\")\n",
    "print(\"   Starting with 200 fonts to test (about 2,000 images)\")\n",
    "print(\"   This should take 3-5 minutes...\\n\")\n",
    "\n",
    "dataset_info = generator.generate_dataset(\n",
    "    samples_per_font=10,\n",
    "    max_fonts=200  # Start with 200 fonts, can increase to all 3,083 later\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Dataset ready!\")\n",
    "print(f\"   Location: training_data/\")\n",
    "print(f\"   Ready for Step 3: Model Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f4ec1273-85bd-4602-95fc-f717da956186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 3: TRAINING THE MODEL\n",
      "============================================================\n",
      "\n",
      "üì¶ Installing training packages...\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.50.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets) (3.12.13)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.10.0.dev20251110+cu128)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.5.1+gitbfeb0668 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5.1+gitbfeb0668)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "\n",
      "üîß Preparing dataset and model...\n",
      "   Loading dataset from training_data/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e205a59460f49d0bfacf8e61bf7dbc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Dataset loaded:\n",
      "   Total samples: 2000\n",
      "   Number of font classes: 105\n",
      "\n",
      "üìù Sample font families (first 10):\n",
      "   0. abeezee\n",
      "   1. abel\n",
      "   2. abhayalibre\n",
      "   3. aboreto\n",
      "   4. abrilfatface\n",
      "   5. abyssinicasil\n",
      "   6. aclonica\n",
      "   7. acme\n",
      "   8. actor\n",
      "   9. adamina\n",
      "   ... and 95 more\n",
      "\n",
      "ü§ñ Loading base model (ResNet-18)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([105]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([105, 512]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Base model loaded\n",
      "\n",
      "üîÑ Preprocessing images...\n",
      "   Splitting into train/validation sets...\n",
      "   Training samples: 1600\n",
      "   Validation samples: 400\n",
      "============================================================\n",
      "STEP 3: TRAINING THE MODEL (CPU MODE)\n",
      "============================================================\n",
      "\n",
      "üì¶ Installing training packages...\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.12/site-packages (4.50.3)\n",
      "Requirement already satisfied: datasets in /opt/conda/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.12/site-packages (1.11.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.12/site-packages (1.7.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.36.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.12/site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.12/site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.21.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/conda/lib/python3.12/site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.12/site-packages (from transformers) (4.67.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/conda/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.12/site-packages (from datasets) (3.12.13)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.12/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/conda/lib/python3.12/site-packages (from accelerate) (2.10.0.dev20251110+cu128)\n",
      "Requirement already satisfied: scipy>=1.8.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.16.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /opt/conda/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (6.6.3)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.12/site-packages (from aiohttp->datasets) (1.20.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/conda/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (1.2.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.12/site-packages (from requests->transformers) (2024.7.4)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.5.1+gitbfeb0668 in /opt/conda/lib/python3.12/site-packages (from torch>=2.0.0->accelerate) (3.5.1+gitbfeb0668)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.12/site-packages (from pandas->datasets) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "\n",
      "üîß Preparing dataset and model...\n",
      "   Running on CPU for stability\n",
      "   Loading dataset from training_data/...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ac937b4ef3d43eca4c11954240e268c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/2000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Dataset loaded:\n",
      "   Total samples: 2000\n",
      "   Number of font classes: 105\n",
      "\n",
      "üìù Sample font families (first 10):\n",
      "   0. abeezee\n",
      "   1. abel\n",
      "   2. abhayalibre\n",
      "   3. aboreto\n",
      "   4. abrilfatface\n",
      "   5. abyssinicasil\n",
      "   6. aclonica\n",
      "   7. acme\n",
      "   8. actor\n",
      "   9. adamina\n",
      "   ... and 95 more\n",
      "\n",
      "ü§ñ Loading base model (ResNet-18)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([105]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([105, 512]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1626: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Base model loaded\n",
      "\n",
      "üîÑ Preprocessing images...\n",
      "   Splitting into train/validation sets...\n",
      "   Training samples: 1600\n",
      "   Validation samples: 400\n",
      "\n",
      "‚öôÔ∏è Configuring training for CPU...\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Device: CPU\n",
      "   Epochs: 10\n",
      "   Batch size: 8\n",
      "   Learning rate: 5e-05\n",
      "   Estimated time: 20-30 minutes on CPU\n",
      "\n",
      "üöÄ Starting training...\n",
      "   This will take 20-30 minutes on CPU\n",
      "   You'll see progress updates every 20 steps\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:47, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>3.846900</td>\n",
       "      <td>3.593700</td>\n",
       "      <td>0.220000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.742800</td>\n",
       "      <td>2.640650</td>\n",
       "      <td>0.390000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.987900</td>\n",
       "      <td>2.057560</td>\n",
       "      <td>0.480000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.451200</td>\n",
       "      <td>1.673101</td>\n",
       "      <td>0.585000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.127800</td>\n",
       "      <td>1.459094</td>\n",
       "      <td>0.622500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.853500</td>\n",
       "      <td>1.315969</td>\n",
       "      <td>0.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.620400</td>\n",
       "      <td>1.186008</td>\n",
       "      <td>0.675000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.548600</td>\n",
       "      <td>1.175683</td>\n",
       "      <td>0.682500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.480900</td>\n",
       "      <td>1.104331</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.376200</td>\n",
       "      <td>1.085691</td>\n",
       "      <td>0.707500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Training complete!\n",
      "============================================================\n",
      "\n",
      "üìä Final Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Final Accuracy: 70.75%\n",
      "   Final Loss: 1.1043\n",
      "\n",
      "üíæ Saving model...\n",
      "\n",
      "‚úÖ Model saved to: ./tesserae_google_fonts_model\n",
      "\n",
      "üéâ Training complete! Ready for Step 4: Testing\n",
      "\n",
      "üöÄ Starting training...\n",
      "   This will take 15-25 minutes depending on GPU availability\n",
      "   You'll see progress updates every 20 steps\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2000' max='2000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2000/2000 08:43, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.585300</td>\n",
       "      <td>1.078112</td>\n",
       "      <td>0.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.381800</td>\n",
       "      <td>1.113507</td>\n",
       "      <td>0.717500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.229200</td>\n",
       "      <td>0.966514</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.110800</td>\n",
       "      <td>0.965190</td>\n",
       "      <td>0.757500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.067000</td>\n",
       "      <td>0.871591</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.103700</td>\n",
       "      <td>0.896884</td>\n",
       "      <td>0.755000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.077800</td>\n",
       "      <td>0.890424</td>\n",
       "      <td>0.760000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.924720</td>\n",
       "      <td>0.767500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.015200</td>\n",
       "      <td>0.853834</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.047000</td>\n",
       "      <td>0.866165</td>\n",
       "      <td>0.777500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Training complete!\n",
      "============================================================\n",
      "\n",
      "üìä Final Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='50' max='50' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [50/50 00:05]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Final Accuracy: 77.75%\n",
      "   Final Loss: 0.8538\n",
      "\n",
      "üíæ Saving model...\n",
      "\n",
      "‚úÖ Model saved to: ./tesserae_google_fonts_model\n",
      "\n",
      "üéâ Training complete! Ready for Step 4: Testing\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 3: TRAINING THE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Install transformers for training\n",
    "print(\"\\nüì¶ Installing training packages...\")\n",
    "!pip install transformers datasets accelerate scikit-learn\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"\\nüîß Preparing dataset and model...\")\n",
    "\n",
    "# Load dataset from the images we generated\n",
    "print(\"   Loading dataset from training_data/...\")\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"training_data\")\n",
    "\n",
    "print(f\"\\nüìä Dataset loaded:\")\n",
    "print(f\"   Total samples: {len(dataset['train'])}\")\n",
    "print(f\"   Number of font classes: {dataset['train'].features['label'].num_classes}\")\n",
    "\n",
    "# Get label information\n",
    "labels = dataset['train'].features['label'].names\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "print(f\"\\nüìù Sample font families (first 10):\")\n",
    "for i, label in enumerate(labels[:10]):\n",
    "    print(f\"   {i}. {label}\")\n",
    "print(f\"   ... and {len(labels) - 10} more\")\n",
    "\n",
    "# Load base model (ResNet-18 - same as gaborcselle used)\n",
    "print(\"\\nü§ñ Loading base model (ResNet-18)...\")\n",
    "model_name = \"microsoft/resnet-18\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Create model for fine-tuning\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(\"   ‚úì Base model loaded\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(examples):\n",
    "    \"\"\"Preprocess images for training\"\"\"\n",
    "    images = [img.convert(\"RGB\") for img in examples['image']]\n",
    "    inputs = processor(images, return_tensors='pt')\n",
    "    inputs['labels'] = examples['label']\n",
    "    return inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\nüîÑ Preprocessing images...\")\n",
    "dataset = dataset.map(preprocess, batched=True, remove_columns=['image'])\n",
    "dataset.set_format('torch', columns=['pixel_values', 'labels'])\n",
    "\n",
    "# Split into train/validation (80/20)\n",
    "print(\"   Splitting into train/validation sets...\")\n",
    "dataset = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(f\"   Training samples: {len(dataset['train'])}\")\n",
    "print(f\"   Validation samples: {len(dataset['test'])}\")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate accuracy during training\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "# Training configuration (optimized for quick testing)\n",
    "print(\"=\"*60)\n",
    "print(\"STEP 3: TRAINING THE MODEL (CPU MODE)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Install transformers for training\n",
    "print(\"\\nüì¶ Installing training packages...\")\n",
    "!pip install transformers datasets accelerate scikit-learn\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Force CPU usage to avoid CUDA errors\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "print(\"\\nüîß Preparing dataset and model...\")\n",
    "print(\"   Running on CPU for stability\")\n",
    "\n",
    "# Load dataset from the images we generated\n",
    "print(\"   Loading dataset from training_data/...\")\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"training_data\")\n",
    "\n",
    "print(f\"\\nüìä Dataset loaded:\")\n",
    "print(f\"   Total samples: {len(dataset['train'])}\")\n",
    "print(f\"   Number of font classes: {dataset['train'].features['label'].num_classes}\")\n",
    "\n",
    "# Get label information\n",
    "labels = dataset['train'].features['label'].names\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "print(f\"\\nüìù Sample font families (first 10):\")\n",
    "for i, label in enumerate(labels[:10]):\n",
    "    print(f\"   {i}. {label}\")\n",
    "print(f\"   ... and {len(labels) - 10} more\")\n",
    "\n",
    "# Load base model (ResNet-18)\n",
    "print(\"\\nü§ñ Loading base model (ResNet-18)...\")\n",
    "model_name = \"microsoft/resnet-18\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "# Create model for fine-tuning\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(\"   ‚úì Base model loaded\")\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess(examples):\n",
    "    \"\"\"Preprocess images for training\"\"\"\n",
    "    images = [img.convert(\"RGB\") for img in examples['image']]\n",
    "    inputs = processor(images, return_tensors='pt')\n",
    "    inputs['labels'] = examples['label']\n",
    "    return inputs\n",
    "\n",
    "# Apply preprocessing\n",
    "print(\"\\nüîÑ Preprocessing images...\")\n",
    "dataset = dataset.map(preprocess, batched=True, remove_columns=['image'])\n",
    "dataset.set_format('torch', columns=['pixel_values', 'labels'])\n",
    "\n",
    "# Split into train/validation (80/20)\n",
    "print(\"   Splitting into train/validation sets...\")\n",
    "dataset = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(f\"   Training samples: {len(dataset['train'])}\")\n",
    "print(f\"   Validation samples: {len(dataset['test'])}\")\n",
    "\n",
    "# Define metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"Calculate accuracy during training\"\"\"\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "# Training configuration - REDUCED for CPU\n",
    "print(\"\\n‚öôÔ∏è Configuring training for CPU...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./google_fonts_model_checkpoint\",\n",
    "    num_train_epochs=10,  # Reduced from 20 for CPU\n",
    "    per_device_train_batch_size=8,  # Reduced from 16 for CPU\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=20,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    no_cuda=True,  # Force CPU usage\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"   Device: CPU\")\n",
    "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   Learning rate: {training_args.learning_rate}\")\n",
    "print(f\"   Estimated time: 20-30 minutes on CPU\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"   This will take 20-30 minutes on CPU\")\n",
    "print(\"   You'll see progress updates every 20 steps\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Evaluate final performance\n",
    "print(\"\\nüìä Final Evaluation:\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"   Final Accuracy: {eval_results['eval_accuracy']:.2%}\")\n",
    "print(f\"   Final Loss: {eval_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "print(\"\\nüíæ Saving model...\")\n",
    "model.save_pretrained(\"./tesserae_google_fonts_model\")\n",
    "processor.save_pretrained(\"./tesserae_google_fonts_model\")\n",
    "\n",
    "print(\"\\n‚úÖ Model saved to: ./tesserae_google_fonts_model\")\n",
    "print(\"\\nüéâ Training complete! Ready for Step 4: Testing\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Starting training...\")\n",
    "print(\"   This will take 15-25 minutes depending on GPU availability\")\n",
    "print(\"   You'll see progress updates every 20 steps\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Training complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Evaluate final performance\n",
    "print(\"\\nüìä Final Evaluation:\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"   Final Accuracy: {eval_results['eval_accuracy']:.2%}\")\n",
    "print(f\"   Final Loss: {eval_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Save the final model\n",
    "print(\"\\nüíæ Saving model...\")\n",
    "model.save_pretrained(\"./tesserae_google_fonts_model\")\n",
    "processor.save_pretrained(\"./tesserae_google_fonts_model\")\n",
    "\n",
    "print(\"\\n‚úÖ Model saved to: ./tesserae_google_fonts_model\")\n",
    "print(\"\\nüéâ Training complete! Ready for Step 4: Testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f796224d-d17d-48d9-b7b6-6dcb1e6dbd44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "STEP 4: TESTING YOUR GOOGLE FONTS MODEL\n",
      "============================================================\n",
      "\n",
      "ü§ñ Loading your trained model...\n",
      "‚úÖ Model loaded!\n",
      "   Can identify 105 font families\n",
      "\n",
      "üß™ Testing with test4.png...\n",
      "============================================================\n",
      "\n",
      "üéØ GOOGLE FONTS DETECTION RESULTS:\n",
      "  1. rochester                       11.9%\n",
      "  2. craftygirls                      7.4%\n",
      "  3. homemadeapple                    7.1%\n",
      "  4. kosugi                           4.8%\n",
      "  5. jsmathcmr10                      4.6%\n",
      "\n",
      "============================================================\n",
      "‚úÖ Testing complete!\n",
      "\n",
      "üí° Your model is ready to use in Tesserae!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"STEP 4: TESTING YOUR GOOGLE FONTS MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "print(\"\\nü§ñ Loading your trained model...\")\n",
    "\n",
    "# Load your custom Google Fonts model\n",
    "processor = AutoImageProcessor.from_pretrained(\"./tesserae_google_fonts_model\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"./tesserae_google_fonts_model\")\n",
    "\n",
    "print(\"‚úÖ Model loaded!\")\n",
    "print(f\"   Can identify {len(model.config.id2label)} font families\")\n",
    "\n",
    "def identify_google_font(image_path):\n",
    "    \"\"\"Identify font using your custom Google Fonts model\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get top 5 predictions\n",
    "    top5_prob, top5_idx = torch.topk(probabilities, 5)\n",
    "    \n",
    "    results = []\n",
    "    for prob, idx in zip(top5_prob[0], top5_idx[0]):\n",
    "        results.append({\n",
    "            'font_family': model.config.id2label[idx.item()],\n",
    "            'confidence': prob.item()\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with your test image\n",
    "print(\"\\nüß™ Testing with test4.png...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = identify_google_font(\"test4.png\")\n",
    "\n",
    "print(\"\\nüéØ GOOGLE FONTS DETECTION RESULTS:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"  {i}. {result['font_family']:<30} {result['confidence']:>6.1%}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Testing complete!\")\n",
    "print(\"\\nüí° Your model is ready to use in Tesserae!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6a7282a-fca3-4fc2-b870-9185ede777e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "REGENERATING DATASET - FULL SCALE\n",
      "============================================================\n",
      "\n",
      "üóëÔ∏è Removing old training data...\n",
      "   ‚úì Old data removed\n",
      "\n",
      "üìä Available fonts: 3083\n",
      "\n",
      "‚öôÔ∏è Generation options:\n",
      "   Option A: 500 fonts √ó 25 samples = 12,500 images (~15 min)\n",
      "   Option B: 1000 fonts √ó 25 samples = 25,000 images (~30 min)\n",
      "   Option C: ALL 3,083 fonts √ó 25 samples = 77,075 images (~90 min)\n",
      "\n",
      "üìù Recommendation: Start with Option B (1000 fonts)\n",
      "   This gives good coverage without taking forever\n",
      "\n",
      "üöÄ Starting generation with 1000 fonts, 25 samples each...\n",
      "   This will take approximately 30 minutes\n",
      "   Estimated total: 25,000 images\n",
      "\n",
      "\n",
      "üé® Generating dataset from 1000 fonts...\n",
      "   Creating 25 samples per font\n",
      "   Total target: 25000 images\n",
      "\n",
      "   ‚úì Processed 100/1000 fonts (2500 images generated)\n",
      "   ‚úì Processed 200/1000 fonts (5000 images generated)\n",
      "   ‚úì Processed 300/1000 fonts (7500 images generated)\n",
      "   ‚úì Processed 400/1000 fonts (10000 images generated)\n",
      "   ‚úì Processed 500/1000 fonts (12500 images generated)\n",
      "   ‚úì Processed 600/1000 fonts (15000 images generated)\n",
      "   ‚úì Processed 700/1000 fonts (17500 images generated)\n",
      "   ‚úì Processed 800/1000 fonts (20000 images generated)\n",
      "   ‚úì Processed 900/1000 fonts (22500 images generated)\n",
      "   ‚úì Processed 1000/1000 fonts (25000 images generated)\n",
      "\n",
      "‚úÖ Dataset generation complete!\n",
      "   Total images generated: 25000\n",
      "   Unique font families: 466\n",
      "   Failed fonts: 0\n",
      "\n",
      "‚úÖ New dataset ready!\n",
      "   Ready to retrain with much more data\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"REGENERATING DATASET - FULL SCALE\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "# First, let's clean up the old training data\n",
    "print(\"\\nüóëÔ∏è Removing old training data...\")\n",
    "training_dir = Path(\"training_data\")\n",
    "if training_dir.exists():\n",
    "    shutil.rmtree(training_dir)\n",
    "    print(\"   ‚úì Old data removed\")\n",
    "\n",
    "training_dir.mkdir(exist_ok=True)\n",
    "\n",
    "# Recreate generator\n",
    "generator = GoogleFontsDatasetGenerator()\n",
    "\n",
    "# Check how many fonts we have available\n",
    "all_fonts = generator.get_font_files()\n",
    "print(f\"\\nüìä Available fonts: {len(all_fonts)}\")\n",
    "\n",
    "# Decision point: how many to use\n",
    "print(\"\\n‚öôÔ∏è Generation options:\")\n",
    "print(\"   Option A: 500 fonts √ó 25 samples = 12,500 images (~15 min)\")\n",
    "print(\"   Option B: 1000 fonts √ó 25 samples = 25,000 images (~30 min)\")\n",
    "print(\"   Option C: ALL 3,083 fonts √ó 25 samples = 77,075 images (~90 min)\")\n",
    "\n",
    "print(\"\\nüìù Recommendation: Start with Option B (1000 fonts)\")\n",
    "print(\"   This gives good coverage without taking forever\\n\")\n",
    "\n",
    "# Generate with 1000 fonts\n",
    "print(\"üöÄ Starting generation with 1000 fonts, 25 samples each...\")\n",
    "print(\"   This will take approximately 30 minutes\")\n",
    "print(\"   Estimated total: 25,000 images\\n\")\n",
    "\n",
    "dataset_info = generator.generate_dataset(\n",
    "    samples_per_font=25,  # Up from 10\n",
    "    max_fonts=1000  # Up from 200\n",
    ")\n",
    "\n",
    "print(\"\\n‚úÖ New dataset ready!\")\n",
    "print(\"   Ready to retrain with much more data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143b2c41-c9ec-4783-8b2d-34f285f14cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "RETRAINING MODEL WITH EXPANDED DATASET\n",
      "============================================================\n",
      "\n",
      "üîß Loading expanded dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e29baae0d78d454f9366a02d6ab6c4dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043a70801e04401baefcafc7e6661439",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0/25000 [00:00<?, ?files/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00129d0705344626bcb6ba5b039ee511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing checksums:  17%|#7        | 4320/25000 [00:05<00:23, 863.87it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcaed239b74748af9043645d455d68a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä New Dataset Statistics:\n",
      "   Total samples: 25000\n",
      "   Number of font classes: 466\n",
      "   That's 12.5x more data than before!\n",
      "\n",
      "ü§ñ Loading fresh ResNet-18 model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ResNetForImageClassification were not initialized from the model checkpoint at microsoft/resnet-18 and are newly initialized because the shapes did not match:\n",
      "- classifier.1.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([466]) in the model instantiated\n",
      "- classifier.1.weight: found shape torch.Size([1000, 512]) in the checkpoint and torch.Size([466, 512]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   ‚úì Fresh model loaded\n",
      "\n",
      "üîÑ Preprocessing images...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a837a8b9c4e44ad6bc0dce9d4fe67d97",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/25000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Splitting into train/validation sets...\n",
      "   Training samples: 20000\n",
      "   Validation samples: 5000\n",
      "\n",
      "‚öôÔ∏è Configuring training...\n",
      "\n",
      "üìã Training Configuration:\n",
      "   Device: CPU\n",
      "   Epochs: 15\n",
      "   Batch size: 8\n",
      "   Training samples: 20000\n",
      "   Estimated time: 60-90 minutes on CPU (larger dataset)\n",
      "\n",
      "üöÄ Starting retraining...\n",
      "   This will take 60-90 minutes with the larger dataset\n",
      "   You'll see progress updates every 50 steps\n",
      "   Go grab some coffee! ‚òï\n",
      "\n",
      "============================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/transformers/training_args.py:1626: FutureWarning: using `no_cuda` is deprecated and will be removed in version 5.0 of ü§ó Transformers. Use `use_cpu` instead\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='37500' max='37500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [37500/37500 2:42:26, Epoch 15/15]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4.226200</td>\n",
       "      <td>3.815608</td>\n",
       "      <td>0.248400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.497800</td>\n",
       "      <td>1.921287</td>\n",
       "      <td>0.540400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.278900</td>\n",
       "      <td>0.982495</td>\n",
       "      <td>0.744800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.882200</td>\n",
       "      <td>0.633088</td>\n",
       "      <td>0.818200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.484200</td>\n",
       "      <td>0.439687</td>\n",
       "      <td>0.868200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.254100</td>\n",
       "      <td>0.354870</td>\n",
       "      <td>0.893800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.209700</td>\n",
       "      <td>0.298245</td>\n",
       "      <td>0.911000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.151900</td>\n",
       "      <td>0.253947</td>\n",
       "      <td>0.922600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.092100</td>\n",
       "      <td>0.253820</td>\n",
       "      <td>0.923800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.082700</td>\n",
       "      <td>0.256413</td>\n",
       "      <td>0.930200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.059900</td>\n",
       "      <td>0.253098</td>\n",
       "      <td>0.937200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.047200</td>\n",
       "      <td>0.249581</td>\n",
       "      <td>0.941000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.028500</td>\n",
       "      <td>0.254525</td>\n",
       "      <td>0.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.032000</td>\n",
       "      <td>0.255977</td>\n",
       "      <td>0.942800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.023100</td>\n",
       "      <td>0.266701</td>\n",
       "      <td>0.941800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "‚úÖ Retraining complete!\n",
      "============================================================\n",
      "\n",
      "üìä Final Evaluation:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='625' max='625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [625/625 01:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Final Accuracy: 94.28%\n",
      "   Final Loss: 0.2560\n",
      "\n",
      "üíæ Saving improved model...\n",
      "\n",
      "‚úÖ Improved model saved to: ./tesserae_google_fonts_model_v2\n",
      "   This should perform MUCH better than v1!\n",
      "\n",
      "üéâ Ready to test the improved model!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"RETRAINING MODEL WITH EXPANDED DATASET\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification, TrainingArguments, Trainer\n",
    "from datasets import load_dataset\n",
    "from sklearn.metrics import accuracy_score\n",
    "import os\n",
    "\n",
    "# Force CPU usage\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "\n",
    "print(\"\\nüîß Loading expanded dataset...\")\n",
    "dataset = load_dataset(\"imagefolder\", data_dir=\"training_data\")\n",
    "\n",
    "print(f\"\\nüìä New Dataset Statistics:\")\n",
    "print(f\"   Total samples: {len(dataset['train'])}\")\n",
    "print(f\"   Number of font classes: {dataset['train'].features['label'].num_classes}\")\n",
    "print(f\"   That's {len(dataset['train']) / 2000:.1f}x more data than before!\")\n",
    "\n",
    "# Get label information\n",
    "labels = dataset['train'].features['label'].names\n",
    "id2label = {i: label for i, label in enumerate(labels)}\n",
    "label2id = {label: i for i, label in enumerate(labels)}\n",
    "\n",
    "# Load fresh base model\n",
    "print(\"\\nü§ñ Loading fresh ResNet-18 model...\")\n",
    "model_name = \"microsoft/resnet-18\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name)\n",
    "\n",
    "model = AutoModelForImageClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(labels),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(\"   ‚úì Fresh model loaded\")\n",
    "\n",
    "# Preprocessing\n",
    "def preprocess(examples):\n",
    "    images = [img.convert(\"RGB\") for img in examples['image']]\n",
    "    inputs = processor(images, return_tensors='pt')\n",
    "    inputs['labels'] = examples['label']\n",
    "    return inputs\n",
    "\n",
    "print(\"\\nüîÑ Preprocessing images...\")\n",
    "dataset = dataset.map(preprocess, batched=True, remove_columns=['image'])\n",
    "dataset.set_format('torch', columns=['pixel_values', 'labels'])\n",
    "\n",
    "# Split train/validation\n",
    "print(\"   Splitting into train/validation sets...\")\n",
    "dataset = dataset['train'].train_test_split(test_size=0.2, seed=42)\n",
    "\n",
    "print(f\"   Training samples: {len(dataset['train'])}\")\n",
    "print(f\"   Validation samples: {len(dataset['test'])}\")\n",
    "\n",
    "# Metrics\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    predictions = predictions.argmax(axis=1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}\n",
    "\n",
    "# Training configuration - increased epochs for better learning\n",
    "print(\"\\n‚öôÔ∏è Configuring training...\")\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./google_fonts_model_v2_checkpoint\",\n",
    "    num_train_epochs=15,  # Increased from 10\n",
    "    per_device_train_batch_size=8,\n",
    "    per_device_eval_batch_size=8,\n",
    "    learning_rate=5e-5,\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    save_total_limit=2,\n",
    "    report_to=\"none\",\n",
    "    no_cuda=True,\n",
    ")\n",
    "\n",
    "print(f\"\\nüìã Training Configuration:\")\n",
    "print(f\"   Device: CPU\")\n",
    "print(f\"   Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"   Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"   Training samples: {len(dataset['train'])}\")\n",
    "print(f\"   Estimated time: 60-90 minutes on CPU (larger dataset)\")\n",
    "\n",
    "# Create trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset['train'],\n",
    "    eval_dataset=dataset['test'],\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "print(\"\\nüöÄ Starting retraining...\")\n",
    "print(\"   This will take 60-90 minutes with the larger dataset\")\n",
    "print(\"   You'll see progress updates every 50 steps\")\n",
    "print(\"   Go grab some coffee! ‚òï\\n\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Train!\n",
    "trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Retraining complete!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Evaluate\n",
    "print(\"\\nüìä Final Evaluation:\")\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"   Final Accuracy: {eval_results['eval_accuracy']:.2%}\")\n",
    "print(f\"   Final Loss: {eval_results['eval_loss']:.4f}\")\n",
    "\n",
    "# Save the improved model\n",
    "print(\"\\nüíæ Saving improved model...\")\n",
    "model.save_pretrained(\"./tesserae_google_fonts_model_v2\")\n",
    "processor.save_pretrained(\"./tesserae_google_fonts_model_v2\")\n",
    "\n",
    "print(\"\\n‚úÖ Improved model saved to: ./tesserae_google_fonts_model_v2\")\n",
    "print(\"   This should perform MUCH better than v1!\")\n",
    "print(\"\\nüéâ Ready to test the improved model!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5dfe7cb-637f-45e2-b77a-55bcbc9293cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "TESTING IMPROVED MODEL (v2)\n",
      "============================================================\n",
      "\n",
      "ü§ñ Loading improved model v2...\n",
      "‚úÖ Model v2 loaded!\n",
      "   Can identify 466 font families\n",
      "   Training accuracy: 94.28%\n",
      "\n",
      "üß™ Testing with test3.png...\n",
      "============================================================\n",
      "\n",
      "üéØ MODEL v2 RESULTS:\n",
      "  1. courierprime                    11.1%\n",
      "  2. areyouserious                    5.3%\n",
      "  3. cutivemono                       5.0%\n",
      "  4. abyssinicasil                    3.7%\n",
      "  5. amethysta                        3.0%\n",
      "\n",
      "üìä Comparison:\n",
      "   v1 (200 fonts): rochester (11.9%) ‚ùå\n",
      "   v2 (1000 fonts): courierprime (11.1%) ‚ö†Ô∏è\n",
      "\n",
      "============================================================\n",
      "\n",
      "üí° Reminder - test4.png contains:\n",
      "   ‚Ä¢ Arial (or similar sans-serif)\n",
      "   ‚Ä¢ Courier New (monospace)\n",
      "   ‚Ä¢ Times New Roman (serif)\n",
      "   ‚Ä¢ Pacifico (script)\n",
      "\n",
      "============================================================\n",
      "‚úÖ Testing complete!\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"TESTING IMPROVED MODEL (v2)\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "print(\"\\nü§ñ Loading improved model v2...\")\n",
    "\n",
    "# Load your improved model\n",
    "processor = AutoImageProcessor.from_pretrained(\"./tesserae_google_fonts_model_v2\")\n",
    "model = AutoModelForImageClassification.from_pretrained(\"./tesserae_google_fonts_model_v2\")\n",
    "\n",
    "print(\"‚úÖ Model v2 loaded!\")\n",
    "print(f\"   Can identify {len(model.config.id2label)} font families\")\n",
    "print(f\"   Training accuracy: 94.28%\")\n",
    "\n",
    "def identify_google_font_v2(image_path):\n",
    "    \"\"\"Identify font using improved v2 model\"\"\"\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    inputs = processor(images=image, return_tensors=\"pt\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "    \n",
    "    # Get top 5 predictions\n",
    "    top5_prob, top5_idx = torch.topk(probabilities, 5)\n",
    "    \n",
    "    results = []\n",
    "    for prob, idx in zip(top5_prob[0], top5_idx[0]):\n",
    "        results.append({\n",
    "            'font_family': model.config.id2label[idx.item()],\n",
    "            'confidence': prob.item()\n",
    "        })\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test with your test image\n",
    "print(\"\\nüß™ Testing with test3.png...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "results = identify_google_font_v2(\"test4.png\")\n",
    "\n",
    "print(\"\\nüéØ MODEL v2 RESULTS:\")\n",
    "for i, result in enumerate(results, 1):\n",
    "    print(f\"  {i}. {result['font_family']:<30} {result['confidence']:>6.1%}\")\n",
    "\n",
    "print(\"\\nüìä Comparison:\")\n",
    "print(\"   v1 (200 fonts): rochester (11.9%) ‚ùå\")\n",
    "print(f\"   v2 (1000 fonts): {results[0]['font_family']} ({results[0]['confidence']:.1%}) {'‚úÖ' if results[0]['confidence'] > 50 else '‚ö†Ô∏è'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "\n",
    "# Let's also check what the actual fonts in test3.png were\n",
    "print(\"\\nüí° Reminder - test4.png contains:\")\n",
    "print(\"   ‚Ä¢ Arial (or similar sans-serif)\")\n",
    "print(\"   ‚Ä¢ Courier New (monospace)\")\n",
    "print(\"   ‚Ä¢ Times New Roman (serif)\")\n",
    "print(\"   ‚Ä¢ Pacifico (script)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ Testing complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d797bf37-a2c7-46fc-8855-9942e1d8c91d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
