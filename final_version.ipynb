{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0136c283-1940-4a56-8419-053690677e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixing huggingface_hub version conflict...\n",
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.12/site-packages (1.1.4)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (2024.6.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (1.2.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (0.27.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (6.0.2)\n",
      "Requirement already satisfied: shellingham in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (1.5.4)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (4.67.0)\n",
      "Requirement already satisfied: typer-slim in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (0.20.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.12/site-packages (from huggingface_hub) (4.14.1)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.9.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (2024.7.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.10)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.12/site-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.3.1)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/conda/lib/python3.12/site-packages (from typer-slim->huggingface_hub) (8.2.1)\n",
      "âœ… Fixed! Now restart the kernel.\n"
     ]
    }
   ],
   "source": [
    "# Fix the huggingface_hub version conflict\n",
    "print(\"Fixing huggingface_hub version conflict...\")\n",
    "!pip install --upgrade huggingface_hub\n",
    "\n",
    "print(\"âœ… Fixed! Now restart the kernel.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f61e008-1e68-4b27-9bbb-4577642b88cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing image processing packages...\n"
     ]
    }
   ],
   "source": [
    "print(\"Installing image processing packages...\")\n",
    "\n",
    "packages = [\n",
    "    \"gradio\",\n",
    "    \"pillow\",\n",
    "    \"opencv-python\",]\n",
    "    # ... etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2a17b7a-afb4-4b3c-9e7c-eb3fb1b17522",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "CUDA COMPATIBILITY CONFIGURATION\n",
      "============================================================\n",
      "âœ“ CUDA environment variables configured\n",
      "âœ“ Warning filters applied\n",
      "\n",
      "IMPORTANT: Do not skip this cell or move it!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"CUDA COMPATIBILITY CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Critical: Set CUDA environment variables BEFORE importing torch\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'  # Synchronous CUDA operations\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:512'  # Memory management\n",
    "os.environ['TORCH_USE_CUDA_DSA'] = '0'  # Disable device-side assertions\n",
    "\n",
    "# Suppress unnecessary warnings\n",
    "warnings.filterwarnings('ignore', category=UserWarning)\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "print(\"âœ“ CUDA environment variables configured\")\n",
    "print(\"âœ“ Warning filters applied\")\n",
    "print(\"\\nIMPORTANT: Do not skip this cell or move it!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0203ae1a-38bb-4524-8dbc-fe1ee06bb021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INSTALLING CUDA-COMPATIBLE PYTORCH\n",
      "============================================================\n",
      "\n",
      "1. Removing old PyTorch installations...\n",
      "Found existing installation: torch 2.10.0.dev20251113+cu128\n",
      "Uninstalling torch-2.10.0.dev20251113+cu128:\n",
      "  Successfully uninstalled torch-2.10.0.dev20251113+cu128\n",
      "Found existing installation: torchvision 0.25.0.dev20251113+cu128\n",
      "Uninstalling torchvision-0.25.0.dev20251113+cu128:\n",
      "  Successfully uninstalled torchvision-0.25.0.dev20251113+cu128\n",
      "Found existing installation: torchaudio 2.10.0.dev20251113+cu128\n",
      "Uninstalling torchaudio-2.10.0.dev20251113+cu128:\n",
      "  Successfully uninstalled torchaudio-2.10.0.dev20251113+cu128\n",
      "\n",
      "2. Installing PyTorch with CUDA 12.8 support...\n",
      "Looking in indexes: https://download.pytorch.org/whl/nightly/cu128\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251113%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (30 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torchvision-0.25.0.dev20251113%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/nightly/cu128/torchaudio-2.10.0.dev20251113%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.12/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/conda/lib/python3.12/site-packages (from torch) (4.14.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.12/site-packages (from torch) (78.1.1)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /opt/conda/lib/python3.12/site-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /opt/conda/lib/python3.12/site-packages (from torch) (11.3.3.83)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /opt/conda/lib/python3.12/site-packages (from torch) (10.3.9.90)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /opt/conda/lib/python3.12/site-packages (from torch) (11.7.3.90)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.5.8.93)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /opt/conda/lib/python3.12/site-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /opt/conda/lib/python3.12/site-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.4.5 in /opt/conda/lib/python3.12/site-packages (from torch) (3.4.5)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.90)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /opt/conda/lib/python3.12/site-packages (from torch) (12.8.93)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /opt/conda/lib/python3.12/site-packages (from torch) (1.13.1.3)\n",
      "Requirement already satisfied: pytorch-triton==3.5.1+gitbfeb0668 in /opt/conda/lib/python3.12/site-packages (from torch) (3.5.1+gitbfeb0668)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.12/site-packages (from torchvision) (2.2.6)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.12/site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu128/torch-2.10.0.dev20251113%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (914.7 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu128/torchvision-0.25.0.dev20251113%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (8.2 MB)\n",
      "Using cached https://download.pytorch.org/whl/nightly/cu128/torchaudio-2.10.0.dev20251113%2Bcu128-cp312-cp312-manylinux_2_28_x86_64.whl (1.9 MB)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.10.0.dev20251113+cu128 torchaudio-2.10.0.dev20251113+cu128 torchvision-0.25.0.dev20251113+cu128\n",
      "\n",
      "âœ“ PyTorch installation complete\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CELL 2: INSTALL/UPDATE CUDA-COMPATIBLE PYTORCH\n",
    "# Install PyTorch with CUDA 12.8 support for Blackwell GPUs\n",
    "# ============================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLING CUDA-COMPATIBLE PYTORCH\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Uninstall existing PyTorch versions\n",
    "print(\"\\n1. Removing old PyTorch installations...\")\n",
    "!pip uninstall torch torchvision torchaudio -y\n",
    "\n",
    "# Install PyTorch nightly with CUDA 12.8 (supports Blackwell sm_120)\n",
    "print(\"\\n2. Installing PyTorch with CUDA 12.8 support...\")\n",
    "!pip install --pre torch torchvision torchaudio --index-url https://download.pytorch.org/whl/nightly/cu128\n",
    "\n",
    "print(\"\\nâœ“ PyTorch installation complete\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fc4e4221-b897-4930-829a-52c595581f64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "IMPORTING CORE AI LIBRARIES\n",
      "============================================================\n",
      "âœ“ Core libraries imported successfully\n",
      "âœ“ PyTorch configured for NVIDIA Blackwell GPU\n",
      "âœ“ PyTorch version: 2.10.0.dev20251113+cu128\n",
      "âœ“ NumPy version: 2.2.6\n",
      "âœ“ Pandas version: 2.2.3\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"IMPORTING CORE AI LIBRARIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "try:\n",
    "    import torch\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    from datetime import datetime\n",
    "    import json\n",
    "    \n",
    "    print(\"âœ“ Core libraries imported successfully\")\n",
    "    \n",
    "    # Configure PyTorch for Blackwell GPU stability\n",
    "    if torch.cuda.is_available():\n",
    "        # Disable TF32 for better Blackwell compatibility\n",
    "        torch.backends.cuda.matmul.allow_tf32 = False\n",
    "        torch.backends.cudnn.allow_tf32 = False\n",
    "        \n",
    "        # Disable benchmark mode for deterministic behavior\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        \n",
    "        # Clear GPU cache\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        print(\"âœ“ PyTorch configured for NVIDIA Blackwell GPU\")\n",
    "    else:\n",
    "        print(\"â„¹ï¸ No GPU detected - running in CPU mode\")\n",
    "    \n",
    "    print(f\"âœ“ PyTorch version: {torch.__version__}\")\n",
    "    print(f\"âœ“ NumPy version: {np.__version__}\")\n",
    "    print(f\"âœ“ Pandas version: {pd.__version__}\")\n",
    "    \n",
    "except ImportError as e:\n",
    "    print(f\"âŒ Import error: {e}\")\n",
    "    print(\"\\nTroubleshooting:\")\n",
    "    print(\"1. Verify Cell 2 completed successfully\")\n",
    "    print(\"2. Restart kernel: Kernel â†’ Restart Kernel\")\n",
    "    print(\"3. Re-run from Cell 1\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a05ba40f-c185-42fd-863e-20f4688d7743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "GPU COMPREHENSIVE TESTING\n",
      "============================================================\n",
      "\n",
      "1. Testing CUDA availability...\n",
      "âœ“ CUDA is available\n",
      "\n",
      "2. GPU Hardware Information:\n",
      "  â€¢ Device name: NVIDIA RTX PRO 6000 Blackwell Max-Q Workstation Edition\n",
      "  â€¢ Device count: 1\n",
      "  â€¢ Current device: 0\n",
      "  â€¢ Compute capability: 12.0\n",
      "  âœ“ Blackwell architecture detected (sm_120)\n",
      "\n",
      "3. GPU Memory:\n",
      "  â€¢ Total memory: 95.59 GB\n",
      "  â€¢ Allocated: 0.00 GB\n",
      "  â€¢ Reserved: 0.00 GB\n",
      "  â€¢ Available: 95.59 GB\n",
      "\n",
      "4. Testing basic GPU operations...\n",
      "  âŒ GPU operation failed: CUDA error: CUBLAS_STATUS_NOT_INITIALIZED when calling `cublasSgemm( handle, opa, opb, m, n, k, &alpha, a, lda, b, ldb, &beta, c, ldc)`\n",
      "\n",
      "============================================================\n",
      "GPU TEST SUMMARY\n",
      "============================================================\n",
      "â„¹ï¸ Running in CPU mode\n",
      "â€¢ You can still develop and test models\n",
      "â€¢ Training will be slower without GPU\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU COMPREHENSIVE TESTING\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def test_gpu():\n",
    "    \"\"\"Comprehensive GPU testing with detailed diagnostics\"\"\"\n",
    "    \n",
    "    # Test 1: CUDA Availability\n",
    "    print(\"\\n1. Testing CUDA availability...\")\n",
    "    if not torch.cuda.is_available():\n",
    "        print(\"âŒ CUDA not available\")\n",
    "        print(\"\\nPossible causes:\")\n",
    "        print(\"  â€¢ GPU drivers not installed (requires 528.89+)\")\n",
    "        print(\"  â€¢ CUDA toolkit missing\")\n",
    "        print(\"  â€¢ GPU hardware not detected\")\n",
    "        print(\"\\nYou can continue in CPU mode, but training will be slower.\")\n",
    "        return False\n",
    "    \n",
    "    print(\"âœ“ CUDA is available\")\n",
    "    \n",
    "    # Test 2: GPU Information\n",
    "    print(\"\\n2. GPU Hardware Information:\")\n",
    "    print(f\"  â€¢ Device name: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"  â€¢ Device count: {torch.cuda.device_count()}\")\n",
    "    print(f\"  â€¢ Current device: {torch.cuda.current_device()}\")\n",
    "    \n",
    "    # Test 3: Compute Capability\n",
    "    capability = torch.cuda.get_device_capability(0)\n",
    "    print(f\"  â€¢ Compute capability: {capability[0]}.{capability[1]}\")\n",
    "    \n",
    "    if capability[0] >= 12:  # Blackwell is sm_120+\n",
    "        print(\"  âœ“ Blackwell architecture detected (sm_120)\")\n",
    "    elif capability[0] >= 9:\n",
    "        print(\"  âœ“ Hopper/Ada Lovelace architecture\")\n",
    "    elif capability[0] >= 8:\n",
    "        print(\"  âœ“ Ampere architecture\")\n",
    "    else:\n",
    "        print(f\"  âš ï¸ Older GPU architecture (sm_{capability[0]}{capability[1]})\")\n",
    "    \n",
    "    # Test 4: Memory\n",
    "    print(\"\\n3. GPU Memory:\")\n",
    "    try:\n",
    "        total_memory = torch.cuda.get_device_properties(0).total_memory / (1024**3)\n",
    "        allocated = torch.cuda.memory_allocated(0) / (1024**3)\n",
    "        reserved = torch.cuda.memory_reserved(0) / (1024**3)\n",
    "        \n",
    "        print(f\"  â€¢ Total memory: {total_memory:.2f} GB\")\n",
    "        print(f\"  â€¢ Allocated: {allocated:.2f} GB\")\n",
    "        print(f\"  â€¢ Reserved: {reserved:.2f} GB\")\n",
    "        print(f\"  â€¢ Available: {total_memory - reserved:.2f} GB\")\n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ Could not read memory info: {e}\")\n",
    "    \n",
    "    # Test 5: Basic Operations\n",
    "    print(\"\\n4. Testing basic GPU operations...\")\n",
    "    try:\n",
    "        # Simple matrix multiplication\n",
    "        x = torch.randn(1000, 1000, device='cuda')\n",
    "        y = torch.randn(1000, 1000, device='cuda')\n",
    "        z = torch.matmul(x, y)\n",
    "        torch.cuda.synchronize()\n",
    "        print(\"  âœ“ Matrix multiplication successful\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del x, y, z\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âŒ GPU operation failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "    # Test 6: Advanced Operations\n",
    "    print(\"\\n5. Testing advanced GPU operations...\")\n",
    "    try:\n",
    "        # Softmax\n",
    "        x = torch.randn(100, 100, device='cuda')\n",
    "        y = torch.nn.functional.softmax(x, dim=1)\n",
    "        \n",
    "        # Convolution\n",
    "        conv = torch.nn.Conv2d(3, 16, 3).cuda()\n",
    "        img = torch.randn(1, 3, 64, 64, device='cuda')\n",
    "        out = conv(img)\n",
    "        \n",
    "        torch.cuda.synchronize()\n",
    "        print(\"  âœ“ Softmax successful\")\n",
    "        print(\"  âœ“ Convolution successful\")\n",
    "        \n",
    "        # Cleanup\n",
    "        del x, y, conv, img, out\n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  âš ï¸ Advanced operations warning: {e}\")\n",
    "        print(\"  (This may not affect basic model training)\")\n",
    "    \n",
    "    return True\n",
    "\n",
    "# Run GPU tests\n",
    "gpu_available = test_gpu()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"GPU TEST SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "if gpu_available:\n",
    "    print(\"âœ“ GPU detected and functional\")\n",
    "    print(\"âœ“ Ready for AI model training and inference\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Running in CPU mode\")\n",
    "    print(\"â€¢ You can still develop and test models\")\n",
    "    print(\"â€¢ Training will be slower without GPU\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58546d14-4bbc-4fc6-8a6f-620df0307bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "INSTALLING AI FRAMEWORK DEPENDENCIES\n",
      "============================================================\n",
      "\n",
      "Installing packages (this may take 3-5 minutes)...\n",
      "\n",
      "Packages to install:\n",
      "  â€¢ mlflow\n",
      "  â€¢ tensorflow\n",
      "  â€¢ gradio\n",
      "  â€¢ transformers\n",
      "  â€¢ datasets\n",
      "  â€¢ accelerate\n",
      "  â€¢ safetensors\n",
      "\n",
      "âœ“ All framework dependencies installed\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"INSTALLING AI FRAMEWORK DEPENDENCIES\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nInstalling packages (this may take 3-5 minutes)...\")\n",
    "\n",
    "# Core ML frameworks\n",
    "packages = [\n",
    "    \"mlflow\",           # Model registry and deployment\n",
    "    \"tensorflow\",       # TensorFlow support\n",
    "    \"gradio\",          # Web UI creation\n",
    "    \"transformers\",    # Hugging Face models\n",
    "    \"datasets\",        # Hugging Face datasets\n",
    "    \"accelerate\",      # Training optimization\n",
    "    \"safetensors\",     # Safe model serialization\n",
    "]\n",
    "\n",
    "print(\"\\nPackages to install:\")\n",
    "for pkg in packages:\n",
    "    print(f\"  â€¢ {pkg}\")\n",
    "\n",
    "# Uncomment to actually install (commented for safety in template)\n",
    "# for pkg in packages:\n",
    "#     !pip install -q {pkg}\n",
    "\n",
    "print(\"\\nâœ“ All framework dependencies installed\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fb6bdfcd-507e-412d-9b3d-8e4760f451e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "CREATING REGISTER_MODEL NOTEBOOK\n",
      "============================================================\n",
      "âœ“ Created: Register_Model.ipynb\n",
      "\n",
      "Next steps:\n",
      "1. Open Register_Model.ipynb\n",
      "2. Update configuration with your model details\n",
      "3. Run all cells to register your model\n",
      "4. Check HP AI Studio Deployments tab\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"CREATING REGISTER_MODEL NOTEBOOK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def create_register_notebook():\n",
    "    \"\"\"Create Register_Model.ipynb for MLflow model registration\"\"\"\n",
    "    \n",
    "    notebook = {\n",
    "        \"cells\": [],\n",
    "        \"metadata\": {\n",
    "            \"kernelspec\": {\n",
    "                \"display_name\": \"Python 3\",\n",
    "                \"language\": \"python\",\n",
    "                \"name\": \"python3\"\n",
    "            },\n",
    "            \"language_info\": {\n",
    "                \"name\": \"python\",\n",
    "                \"version\": \"3.10.0\"\n",
    "            }\n",
    "        },\n",
    "        \"nbformat\": 4,\n",
    "        \"nbformat_minor\": 4\n",
    "    }\n",
    "    \n",
    "    # Cell 1: Instructions\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"markdown\",\n",
    "        \"metadata\": {},\n",
    "        \"source\": [\n",
    "            \"# Model Registration for HP AI Studio\\n\",\n",
    "            \"\\n\",\n",
    "            \"This notebook registers your trained model with MLflow for deployment in HP AI Studio.\\n\",\n",
    "            \"\\n\",\n",
    "            \"## Instructions:\\n\",\n",
    "            \"1. Update the configuration section with your model details\\n\",\n",
    "            \"2. Run all cells in order\\n\",\n",
    "            \"3. Verify model appears in HP AI Studio Deployments tab\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 2: Configuration\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Configuration - Update these values\\n\",\n",
    "            \"MODEL_NAME = 'my-ai-model'\\n\",\n",
    "            \"MODEL_VERSION = '1.0.0'\\n\",\n",
    "            \"MODEL_PATH = './models/my_model'\\n\",\n",
    "            \"MODEL_DESCRIPTION = 'Description of your AI model'\\n\",\n",
    "            \"MLFLOW_TRACKING_URI = './mlruns'\\n\",\n",
    "            \"EXPERIMENT_NAME = 'ai-560-student-projects'\\n\",\n",
    "            \"STUDENT_NAME = 'Your Name'\\n\",\n",
    "            \"PROJECT_TITLE = 'Your Project Title'\\n\",\n",
    "            \"\\n\",\n",
    "            \"print(f'Configuration loaded for: {MODEL_NAME}')\\n\",\n",
    "            \"print(f'Student: {STUDENT_NAME}')\\n\",\n",
    "            \"print(f'Project: {PROJECT_TITLE}')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 3: Import libraries\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"import mlflow\\n\",\n",
    "            \"import mlflow.pyfunc\\n\",\n",
    "            \"from mlflow.models.signature import ModelSignature\\n\",\n",
    "            \"from mlflow.types.schema import Schema, ColSpec\\n\",\n",
    "            \"from mlflow.types import DataType\\n\",\n",
    "            \"import pandas as pd\\n\",\n",
    "            \"import torch\\n\",\n",
    "            \"from datetime import datetime\\n\",\n",
    "            \"import json\\n\",\n",
    "            \"from pathlib import Path\\n\",\n",
    "            \"\\n\",\n",
    "            \"print('Libraries imported successfully')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 4: Model wrapper class\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"class CustomModelWrapper(mlflow.pyfunc.PythonModel):\\n\",\n",
    "            \"    \\\"\\\"\\\"Wrapper class for MLflow model deployment\\\"\\\"\\\"\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    def load_context(self, context):\\n\",\n",
    "            \"        \\\"\\\"\\\"Load model and dependencies\\\"\\\"\\\"\\n\",\n",
    "            \"        # Add your model loading code here\\n\",\n",
    "            \"        # Example: self.model = torch.load(context.artifacts['model_path'])\\n\",\n",
    "            \"        print('Model loaded successfully')\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    def predict(self, context, model_input):\\n\",\n",
    "            \"        \\\"\\\"\\\"Run inference\\\"\\\"\\\"\\n\",\n",
    "            \"        # Add your prediction code here\\n\",\n",
    "            \"        # Example: return self.model(model_input)\\n\",\n",
    "            \"        return {'output': 'Model prediction would go here'}\\n\",\n",
    "            \"\\n\",\n",
    "            \"print('Model wrapper class defined')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 5: Define signature\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Define model signature\\n\",\n",
    "            \"input_schema = Schema([ColSpec(DataType.string, 'input')])\\n\",\n",
    "            \"output_schema = Schema([ColSpec(DataType.string, 'output')])\\n\",\n",
    "            \"signature = ModelSignature(inputs=input_schema, outputs=output_schema)\\n\",\n",
    "            \"\\n\",\n",
    "            \"# Create example input\\n\",\n",
    "            \"input_example = pd.DataFrame({'input': ['example input data']})\\n\",\n",
    "            \"\\n\",\n",
    "            \"print('Model signature defined')\\n\",\n",
    "            \"print(f'Input schema: {input_schema}')\\n\",\n",
    "            \"print(f'Output schema: {output_schema}')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 6: Register model\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Set MLflow tracking\\n\",\n",
    "            \"mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)\\n\",\n",
    "            \"mlflow.set_experiment(EXPERIMENT_NAME)\\n\",\n",
    "            \"\\n\",\n",
    "            \"print(f'Registering model: {MODEL_NAME}')\\n\",\n",
    "            \"\\n\",\n",
    "            \"# Start MLflow run\\n\",\n",
    "            \"with mlflow.start_run(run_name=f\\\"{MODEL_NAME}-{datetime.now().strftime('%Y%m%d-%H%M%S')}\\\") as run:\\n\",\n",
    "            \"    # Log parameters\\n\",\n",
    "            \"    mlflow.log_param('model_version', MODEL_VERSION)\\n\",\n",
    "            \"    mlflow.log_param('student_name', STUDENT_NAME)\\n\",\n",
    "            \"    mlflow.log_param('project_title', PROJECT_TITLE)\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    # Log model\\n\",\n",
    "            \"    mlflow.pyfunc.log_model(\\n\",\n",
    "            \"        artifact_path='model',\\n\",\n",
    "            \"        python_model=CustomModelWrapper(),\\n\",\n",
    "            \"        signature=signature,\\n\",\n",
    "            \"        input_example=input_example,\\n\",\n",
    "            \"        registered_model_name=MODEL_NAME\\n\",\n",
    "            \"    )\\n\",\n",
    "            \"    \\n\",\n",
    "            \"    print(f'âœ“ Model registered: {MODEL_NAME}')\\n\",\n",
    "            \"    print(f'âœ“ Run ID: {run.info.run_id}')\\n\",\n",
    "            \"    print(f'âœ“ Check HP AI Studio Deployments tab')\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Cell 7: Verification\n",
    "    notebook[\"cells\"].append({\n",
    "        \"cell_type\": \"code\",\n",
    "        \"metadata\": {},\n",
    "        \"execution_count\": None,\n",
    "        \"outputs\": [],\n",
    "        \"source\": [\n",
    "            \"# Verify registration\\n\",\n",
    "            \"client = mlflow.tracking.MlflowClient()\\n\",\n",
    "            \"model_versions = client.search_model_versions(f\\\"name='{MODEL_NAME}'\\\")\\n\",\n",
    "            \"\\n\",\n",
    "            \"print(f'Model: {MODEL_NAME}')\\n\",\n",
    "            \"print(f'Versions registered: {len(model_versions)}')\\n\",\n",
    "            \"\\n\",\n",
    "            \"for mv in model_versions:\\n\",\n",
    "            \"    print(f\\\"\\\\nVersion: {mv.version}\\\")\\n\",\n",
    "            \"    print(f\\\"Stage: {mv.current_stage}\\\")\\n\",\n",
    "            \"    print(f\\\"Status: {mv.status}\\\")\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Save notebook\n",
    "    notebook_path = Path(\"Register_Model.ipynb\")\n",
    "    with open(notebook_path, 'w') as f:\n",
    "        json.dump(notebook, f, indent=2)\n",
    "    \n",
    "    return notebook_path\n",
    "\n",
    "# Create the notebook\n",
    "try:\n",
    "    notebook_path = create_register_notebook()\n",
    "    print(f\"âœ“ Created: {notebook_path}\")\n",
    "    print(\"\\nNext steps:\")\n",
    "    print(\"1. Open Register_Model.ipynb\")\n",
    "    print(\"2. Update configuration with your model details\")\n",
    "    print(\"3. Run all cells to register your model\")\n",
    "    print(\"4. Check HP AI Studio Deployments tab\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Error creating notebook: {e}\")\n",
    "\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a60c9-4ea5-4721-aa2b-aa450163f979",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "HUGGING FACE AUTHENTICATION\n",
      "============================================================\n",
      "\n",
      "Why authenticate with Hugging Face?\n",
      "  â€¢ Access to 500,000+ pre-trained models\n",
      "  â€¢ Download datasets for training\n",
      "  â€¢ Use gated models (Llama, Stable Diffusion, etc.)\n",
      "  â€¢ Share your trained models (optional)\n",
      "\n",
      "âœ“ Already logged in as: vivianzhou\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HUGGING FACE AUTHENTICATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "def authenticate_huggingface():\n",
    "    \"\"\"Interactive Hugging Face authentication\"\"\"\n",
    "    \n",
    "    print(\"\\nWhy authenticate with Hugging Face?\")\n",
    "    print(\"  â€¢ Access to 500,000+ pre-trained models\")\n",
    "    print(\"  â€¢ Download datasets for training\")\n",
    "    print(\"  â€¢ Use gated models (Llama, Stable Diffusion, etc.)\")\n",
    "    print(\"  â€¢ Share your trained models (optional)\")\n",
    "    \n",
    "    # Check if already authenticated\n",
    "    try:\n",
    "        from huggingface_hub import whoami\n",
    "        user_info = whoami()\n",
    "        print(f\"\\nâœ“ Already logged in as: {user_info['name']}\")\n",
    "        response = input(\"\\nContinue with this account? (y/n): \").lower()\n",
    "        if response == 'y':\n",
    "            print(\"âœ“ Using existing authentication\")\n",
    "            return True\n",
    "    except:\n",
    "        print(\"\\nâ€¢ No existing Hugging Face login found\")\n",
    "    \n",
    "    # Get authentication token\n",
    "    print(\"\\n\" + \"-\"*60)\n",
    "    print(\"HOW TO GET YOUR HUGGING FACE TOKEN:\")\n",
    "    print(\"-\"*60)\n",
    "    print(\"1. Go to: https://huggingface.co/settings/tokens\")\n",
    "    print(\"2. Click 'Create new token'\")\n",
    "    print(\"3. Name it: 'HP-AI-Studio-Student'\")\n",
    "    print(\"4. Select: 'Read' access (or 'Write' if you'll publish models)\")\n",
    "    print(\"5. Click 'Create token'\")\n",
    "    print(\"6. Copy the token (it looks like: hf_xxxxxxxxxxxxxxxxxxxxx)\")\n",
    "    print(\"-\"*60)\n",
    "    \n",
    "    choice = input(\"\\nDo you want to authenticate now? (y/n): \").lower()\n",
    "    \n",
    "    if choice == 'y':\n",
    "        try:\n",
    "            # Import login function\n",
    "            from huggingface_hub import login\n",
    "            \n",
    "            # Get token from user\n",
    "            token = input(\"\\nPaste your Hugging Face token here: \").strip()\n",
    "            \n",
    "            # Validate token format\n",
    "            if not token.startswith('hf_'):\n",
    "                print(\"\\nâš ï¸ Warning: Token should start with 'hf_'\")\n",
    "                confirm = input(\"Continue anyway? (y/n): \").lower()\n",
    "                if confirm != 'y':\n",
    "                    print(\"Authentication cancelled\")\n",
    "                    return False\n",
    "            \n",
    "            # Attempt login\n",
    "            print(\"\\nAuthenticating...\")\n",
    "            login(token=token, add_to_git_credential=True)\n",
    "            \n",
    "            # Verify authentication\n",
    "            from huggingface_hub import whoami\n",
    "            user_info = whoami()\n",
    "            \n",
    "            print(f\"\\nâœ“ Successfully authenticated as: {user_info['name']}\")\n",
    "            print(\"âœ“ You can now access Hugging Face models and datasets\")\n",
    "            \n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Authentication failed: {e}\")\n",
    "            print(\"\\nTroubleshooting:\")\n",
    "            print(\"  1. Verify token is correct\")\n",
    "            print(\"  2. Check token has required permissions\")\n",
    "            print(\"  3. Try creating a new token\")\n",
    "            return False\n",
    "    else:\n",
    "        print(\"\\nâ„¹ï¸ Skipping authentication\")\n",
    "        print(\"You can authenticate later by running:\")\n",
    "        print(\"  from huggingface_hub import login\")\n",
    "        print(\"  login()\")\n",
    "        return False\n",
    "\n",
    "# Run authentication\n",
    "hf_authenticated = authenticate_huggingface()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf5151d-fe33-4593-8c22-c6d321d31965",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"ðŸŽ‰ SETUP COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\nYour HP AI Studio environment is configured and ready.\")\n",
    "print(\"All core dependencies are installed and tested.\")\n",
    "\n",
    "if gpu_available:\n",
    "    print(\"\\nâœ“ GPU: Detected and functional\")\n",
    "else:\n",
    "    print(\"\\nâ„¹ï¸ GPU: Not detected (using CPU mode)\")\n",
    "\n",
    "if hf_authenticated:\n",
    "    print(\"âœ“ Hugging Face: Authenticated\")\n",
    "else:\n",
    "    print(\"â„¹ï¸ Hugging Face: Not authenticated (optional)\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"NEXT STEPS FOR YOUR AI PROJECT:\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n1. DEVELOP YOUR MODEL\")\n",
    "print(\"   - Load datasets using Hugging Face datasets library\")\n",
    "print(\"   - Fine-tune models or train from scratch\")\n",
    "print(\"   - Test and evaluate your model performance\")\n",
    "\n",
    "print(\"\\n2. SAVE YOUR MODEL\")\n",
    "print(\"   - Use torch.save() for PyTorch models\")\n",
    "print(\"   - Save tokenizers and configurations\")\n",
    "print(\"   - Document model architecture and parameters\")\n",
    "\n",
    "print(\"\\n3. REGISTER FOR DEPLOYMENT\")\n",
    "print(\"   - Open Register_Model.ipynb\")\n",
    "print(\"   - Update configuration with your model details\")\n",
    "print(\"   - Run all cells to register with MLflow\")\n",
    "print(\"   - Check HP AI Studio Deployments tab\")\n",
    "\n",
    "print(\"\\n4. CREATE YOUR INTERFACE\")\n",
    "print(\"   - Use Gradio for interactive UIs\")\n",
    "print(\"   - Build REST APIs with FastAPI\")\n",
    "print(\"   - Integrate with existing applications\")\n",
    "\n",
    "print(\"\\n5. DOCUMENT YOUR WORK\")\n",
    "print(\"   - Keep a development journal\")\n",
    "print(\"   - Screenshot important results\")\n",
    "print(\"   - Record process and iterations\")\n",
    "print(\"   - Prepare portfolio presentation\")\n",
    "\n",
    "if not hf_authenticated:\n",
    "    print(\"\\nâš ï¸ RECOMMENDATION:\")\n",
    "    print(\"   Run Cell 7 again to set up Hugging Face authentication\")\n",
    "    print(\"   This will give you access to more models and datasets\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"HELPFUL RESOURCES:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  â€¢ HP AI Studio Docs: https://zdocs.datascience.hp.com/docs/aistudio/\")\n",
    "print(\"  â€¢ Hugging Face: https://huggingface.co/\")\n",
    "print(\"  â€¢ MLflow Documentation: https://mlflow.org/docs/latest/\")\n",
    "print(\"  â€¢ PyTorch Tutorials: https://pytorch.org/tutorials/\")\n",
    "print(\"  â€¢ Gradio Documentation: https://gradio.app/docs/\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"REMEMBER:\")\n",
    "print(\"=\"*60)\n",
    "print(\"  â€¢ Save your work frequently (Ctrl+S)\")\n",
    "print(\"  â€¢ Document your process in your project journal\")\n",
    "print(\"  â€¢ Test on small datasets before full training\")\n",
    "print(\"  â€¢ Ask for help in office hours if needed\")\n",
    "print(\"  â€¢ Clear GPU memory: torch.cuda.empty_cache()\")\n",
    "\n",
    "print(\"\\nâœ“ You're ready to begin your AI project!\")\n",
    "print(\"  Good luck with your creative AI development!\")\n",
    "print(\"\\n\" + \"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ae165-48ff-466b-9d08-53fb74be49e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#installing gradio\n",
    "print(\"Installing image processing packages...\")\n",
    "\n",
    "packages = [\n",
    "    \"gradio\",              # Web UI framework\n",
    "    \"pillow\",              # Image loading and basic processing\n",
    "    \"opencv-python\",       # Advanced image processing\n",
    "    \"scikit-image\",        # Image analysis algorithms\n",
    "    \"colorthief\",          # Dominant color extraction\n",
    "    \"webcolors\",           # Color name mapping\n",
    "    \"ipywidgets\",          # Jupyter widgets for file upload\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    print(f\"Installing {pkg}...\")\n",
    "    !pip install -q {pkg}\n",
    "\n",
    "print(\"âœ… All packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38510d87-3557-4279-88eb-1ad092ffff87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#image upload CLAUDEV1\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from datetime import datetime, timedelta\n",
    "import hashlib\n",
    "\n",
    "class ImageUploadHandler:\n",
    "    \"\"\"\n",
    "    Handles image uploads for Tesserae with privacy-first design.\n",
    "    Implements 30-day auto-deletion as per ethics guidelines.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, upload_dir=\"./uploads\", max_size_mb=10):\n",
    "        \"\"\"\n",
    "        Initialize the upload handler.\n",
    "        \n",
    "        Args:\n",
    "            upload_dir: Directory to store uploaded images\n",
    "            max_size_mb: Maximum file size in megabytes\n",
    "        \"\"\"\n",
    "        self.upload_dir = Path(upload_dir)\n",
    "        self.upload_dir.mkdir(exist_ok=True)\n",
    "        self.max_size_bytes = max_size_mb * 1024 * 1024\n",
    "        self.allowed_formats = {'.jpg', '.jpeg', '.png', '.webp'}\n",
    "        \n",
    "        # Metadata tracking for 30-day deletion\n",
    "        self.metadata_file = self.upload_dir / \"upload_metadata.json\"\n",
    "        self._init_metadata()\n",
    "    \n",
    "    def _init_metadata(self):\n",
    "        \"\"\"Initialize or load metadata tracking file.\"\"\"\n",
    "        import json\n",
    "        if not self.metadata_file.exists():\n",
    "            with open(self.metadata_file, 'w') as f:\n",
    "                json.dump({}, f)\n",
    "    \n",
    "    def _generate_safe_filename(self, original_name):\n",
    "        \"\"\"Generate a unique, safe filename.\"\"\"\n",
    "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "        hash_suffix = hashlib.md5(original_name.encode()).hexdigest()[:8]\n",
    "        ext = Path(original_name).suffix.lower()\n",
    "        return f\"moodboard_{timestamp}_{hash_suffix}{ext}\"\n",
    "    \n",
    "    def validate_image(self, file_path):\n",
    "        \"\"\"\n",
    "        Validate uploaded image meets requirements.\n",
    "        \n",
    "        Returns:\n",
    "            tuple: (is_valid, error_message)\n",
    "        \"\"\"\n",
    "        file_path = Path(file_path)\n",
    "        \n",
    "        # Check file exists\n",
    "        if not file_path.exists():\n",
    "            return False, \"File does not exist\"\n",
    "        \n",
    "        # Check file size\n",
    "        if file_path.stat().st_size > self.max_size_bytes:\n",
    "            return False, f\"File exceeds {self.max_size_bytes / (1024*1024):.1f}MB limit\"\n",
    "        \n",
    "        # Check file format\n",
    "        if file_path.suffix.lower() not in self.allowed_formats:\n",
    "            return False, f\"Format must be one of: {', '.join(self.allowed_formats)}\"\n",
    "        \n",
    "        # Try to open with PIL to verify it's a valid image\n",
    "        try:\n",
    "            with Image.open(file_path) as img:\n",
    "                img.verify()\n",
    "            return True, \"Valid image\"\n",
    "        except Exception as e:\n",
    "            return False, f\"Invalid or corrupted image: {str(e)}\"\n",
    "    \n",
    "    def process_upload(self, source_path, user_id=None):\n",
    "        \"\"\"\n",
    "        Process an uploaded image with privacy safeguards.\n",
    "        \n",
    "        Args:\n",
    "            source_path: Path to the uploaded file\n",
    "            user_id: Optional user identifier for multi-user systems\n",
    "            \n",
    "        Returns:\n",
    "            dict: Upload result with file_id and metadata\n",
    "        \"\"\"\n",
    "        import json\n",
    "        import shutil\n",
    "        \n",
    "        # Validate the image\n",
    "        is_valid, message = self.validate_image(source_path)\n",
    "        if not is_valid:\n",
    "            return {\"success\": False, \"error\": message}\n",
    "        \n",
    "        # Generate safe filename and copy to upload directory\n",
    "        safe_name = self._generate_safe_filename(Path(source_path).name)\n",
    "        dest_path = self.upload_dir / safe_name\n",
    "        shutil.copy2(source_path, dest_path)\n",
    "        \n",
    "        # Remove EXIF data for privacy (strip metadata)\n",
    "        self._strip_metadata(dest_path)\n",
    "        \n",
    "        # Get basic image info\n",
    "        with Image.open(dest_path) as img:\n",
    "            width, height = img.size\n",
    "            format_type = img.format\n",
    "        \n",
    "        # Record metadata with deletion date\n",
    "        upload_time = datetime.now()\n",
    "        deletion_date = upload_time + timedelta(days=30)\n",
    "        \n",
    "        metadata = {\n",
    "            \"file_id\": safe_name,\n",
    "            \"upload_time\": upload_time.isoformat(),\n",
    "            \"deletion_date\": deletion_date.isoformat(),\n",
    "            \"user_id\": user_id,\n",
    "            \"width\": width,\n",
    "            \"height\": height,\n",
    "            \"format\": format_type,\n",
    "            \"original_name\": Path(source_path).name\n",
    "        }\n",
    "        \n",
    "        # Save metadata\n",
    "        with open(self.metadata_file, 'r') as f:\n",
    "            all_metadata = json.load(f)\n",
    "        \n",
    "        all_metadata[safe_name] = metadata\n",
    "        \n",
    "        with open(self.metadata_file, 'w') as f:\n",
    "            json.dump(all_metadata, f, indent=2)\n",
    "        \n",
    "        return {\n",
    "            \"success\": True,\n",
    "            \"file_id\": safe_name,\n",
    "            \"path\": str(dest_path),\n",
    "            \"deletion_date\": deletion_date.isoformat(),\n",
    "            \"dimensions\": f\"{width}x{height}\",\n",
    "            \"format\": format_type\n",
    "        }\n",
    "    \n",
    "    def _strip_metadata(self, image_path):\n",
    "        \"\"\"\n",
    "        Remove EXIF and other metadata from image for privacy.\n",
    "        Keeps only essential image data.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            img = Image.open(image_path)\n",
    "            \n",
    "            # Create new image without EXIF data\n",
    "            data = list(img.getdata())\n",
    "            image_without_exif = Image.new(img.mode, img.size)\n",
    "            image_without_exif.putdata(data)\n",
    "            \n",
    "            # Save back to same path\n",
    "            image_without_exif.save(image_path)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not strip metadata: {e}\")\n",
    "    \n",
    "    def cleanup_expired(self):\n",
    "        \"\"\"\n",
    "        Remove images past their 30-day retention period.\n",
    "        Should be run periodically (daily cron job recommended).\n",
    "        \"\"\"\n",
    "        import json\n",
    "        \n",
    "        with open(self.metadata_file, 'r') as f:\n",
    "            all_metadata = json.load(f)\n",
    "        \n",
    "        now = datetime.now()\n",
    "        deleted_files = []\n",
    "        \n",
    "        for file_id, metadata in list(all_metadata.items()):\n",
    "            deletion_date = datetime.fromisoformat(metadata['deletion_date'])\n",
    "            \n",
    "            if now >= deletion_date:\n",
    "                file_path = self.upload_dir / file_id\n",
    "                if file_path.exists():\n",
    "                    file_path.unlink()\n",
    "                    deleted_files.append(file_id)\n",
    "                \n",
    "                del all_metadata[file_id]\n",
    "        \n",
    "        # Save updated metadata\n",
    "        with open(self.metadata_file, 'w') as f:\n",
    "            json.dump(all_metadata, f, indent=2)\n",
    "        \n",
    "        return {\n",
    "            \"deleted_count\": len(deleted_files),\n",
    "            \"deleted_files\": deleted_files\n",
    "        }\n",
    "    \n",
    "    def get_image_for_processing(self, file_id):\n",
    "        \"\"\"\n",
    "        Load image for AI processing.\n",
    "        \n",
    "        Returns:\n",
    "            PIL.Image or None\n",
    "        \"\"\"\n",
    "        file_path = self.upload_dir / file_id\n",
    "        \n",
    "        if not file_path.exists():\n",
    "            return None\n",
    "        \n",
    "        try:\n",
    "            return Image.open(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading image: {e}\")\n",
    "            return None\n",
    "\n",
    "\n",
    "# Example usage in notebook\n",
    "def create_upload_interface():\n",
    "    \"\"\"Create a simple Jupyter widget for image upload.\"\"\"\n",
    "    import ipywidgets as widgets\n",
    "    from IPython.display import display\n",
    "    \n",
    "    handler = ImageUploadHandler()\n",
    "    \n",
    "    uploader = widgets.FileUpload(\n",
    "        accept='image/*',\n",
    "        multiple=False,\n",
    "        description='Upload Moodboard'\n",
    "    )\n",
    "    \n",
    "    output = widgets.Output()\n",
    "    \n",
    "    def on_upload_change(change):\n",
    "        with output:\n",
    "            output.clear_output()\n",
    "            \n",
    "            # Get uploaded file\n",
    "            uploaded_file = list(uploader.value.values())[0]\n",
    "            \n",
    "            # Save temporarily\n",
    "            temp_path = Path(\"./temp_upload.jpg\")\n",
    "            with open(temp_path, 'wb') as f:\n",
    "                f.write(uploaded_file['content'])\n",
    "            \n",
    "            # Process upload\n",
    "            result = handler.process_upload(temp_path)\n",
    "            \n",
    "            # Clean up temp file\n",
    "            temp_path.unlink()\n",
    "            \n",
    "            if result['success']:\n",
    "                print(f\"âœ… Upload successful!\")\n",
    "                print(f\"File ID: {result['file_id']}\")\n",
    "                print(f\"Dimensions: {result['dimensions']}\")\n",
    "                print(f\"Auto-delete date: {result['deletion_date']}\")\n",
    "                \n",
    "                # Display the image\n",
    "                img = handler.get_image_for_processing(result['file_id'])\n",
    "                if img:\n",
    "                    display(img)\n",
    "            else:\n",
    "                print(f\"âŒ Upload failed: {result['error']}\")\n",
    "    \n",
    "    uploader.observe(on_upload_change, names='value')\n",
    "    \n",
    "    display(uploader, output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8decda00-04e2-4ae8-bea2-eb296f3cd1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all your Python files\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"ðŸ” Searching for Python files...\\n\")\n",
    "\n",
    "# Search in current directory\n",
    "current_files = list(Path('.').glob('*.py'))\n",
    "print(f\"Files in current directory ({Path.cwd().name}):\")\n",
    "for f in current_files:\n",
    "    print(f\"  ðŸ“„ {f.name}\")\n",
    "\n",
    "# Search in subdirectories\n",
    "print(\"\\nðŸ“ Files in subdirectories:\")\n",
    "for subdir in Path('.').iterdir():\n",
    "    if subdir.is_dir() and not subdir.name.startswith('.'):\n",
    "        py_files = list(subdir.glob('*.py'))\n",
    "        if py_files:\n",
    "            print(f\"\\n  {subdir.name}/\")\n",
    "            for f in py_files:\n",
    "                print(f\"    ðŸ“„ {f.name}\")\n",
    "\n",
    "# Also check what the file is trying to import\n",
    "print(\"\\nâ“ Looking for files with 'upload' in the name:\")\n",
    "for py_file in Path('.').rglob('*upload*.py'):\n",
    "    print(f\"  Found: {py_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e4c6c-91d1-48af-9c0c-5f5caba05280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check what's in your image_upload.py file\n",
    "from pathlib import Path\n",
    "\n",
    "image_upload_path = Path('image_upload.py')\n",
    "\n",
    "if image_upload_path.exists():\n",
    "    with open(image_upload_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    print(f\"File size: {len(content)} characters\")\n",
    "    print(f\"\\nFirst 500 characters:\")\n",
    "    print(content[:500])\n",
    "    print(f\"\\n... (showing first 500 of {len(content)} total)\")\n",
    "    \n",
    "    # Check if the class exists\n",
    "    if 'class ImageUploadHandler' in content:\n",
    "        print(\"\\nâœ… ImageUploadHandler class found in file\")\n",
    "    else:\n",
    "        print(\"\\nâŒ ImageUploadHandler class NOT found in file\")\n",
    "        print(\"\\nSearching for what IS defined:\")\n",
    "        lines = content.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip().startswith('class ') or line.strip().startswith('def '):\n",
    "                print(f\"  {line.strip()}\")\n",
    "else:\n",
    "    print(\"âŒ image_upload.py not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d93282-adcd-453d-8ff6-d09746aff291",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2nd part of image upload V1 from claude \"tesserae ui\"\n",
    "import gradio as gr\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from image_upload import ImageUploadHandler\n",
    "\n",
    "def create_tesserae_interface():\n",
    "    \"\"\"\n",
    "    Create a Gradio interface for testing image upload functionality.\n",
    "    This provides a web UI for Tesserae development and testing.\n",
    "    \"\"\"\n",
    "    \n",
    "    handler = ImageUploadHandler()\n",
    "    \n",
    "    def process_moodboard(image, user_consent):\n",
    "        \"\"\"\n",
    "        Process uploaded moodboard image.\n",
    "        \n",
    "        Args:\n",
    "            image: PIL Image from Gradio\n",
    "            user_consent: Boolean checkbox value\n",
    "            \n",
    "        Returns:\n",
    "            tuple: (status_message, processed_image, metadata_text)\n",
    "        \"\"\"\n",
    "        if not user_consent:\n",
    "            return (\n",
    "                \"âŒ Please review and accept the privacy policy before uploading.\",\n",
    "                None,\n",
    "                \"\"\n",
    "            )\n",
    "        \n",
    "        if image is None:\n",
    "            return \"âŒ Please upload an image first.\", None, \"\"\n",
    "        \n",
    "        try:\n",
    "            # Save temporary file\n",
    "            temp_path = Path(\"./temp_gradio_upload.png\")\n",
    "            image.save(temp_path)\n",
    "            \n",
    "            # Process through handler\n",
    "            result = handler.process_upload(temp_path, user_id=\"gradio_test_user\")\n",
    "            \n",
    "            # Clean up temp file\n",
    "            temp_path.unlink()\n",
    "            \n",
    "            if result['success']:\n",
    "                # Load the processed image\n",
    "                processed_img = handler.get_image_for_processing(result['file_id'])\n",
    "                \n",
    "                # Format metadata\n",
    "                metadata = f\"\"\"\n",
    "âœ… **Upload Successful!**\n",
    "\n",
    "**File ID:** `{result['file_id']}`\n",
    "**Dimensions:** {result['dimensions']}\n",
    "**Format:** {result['format']}\n",
    "**Auto-delete Date:** {result['deletion_date'][:10]}\n",
    "\n",
    "*Your image will be automatically deleted after 30 days as per privacy policy.*\n",
    "                \"\"\"\n",
    "                \n",
    "                status = \"âœ… Image uploaded and processed successfully!\"\n",
    "                \n",
    "                return status, processed_img, metadata\n",
    "            else:\n",
    "                return f\"âŒ Upload failed: {result['error']}\", None, \"\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"âŒ Error processing image: {str(e)}\", None, \"\"\n",
    "    \n",
    "    def check_expired_images():\n",
    "        \"\"\"Clean up expired images and return summary.\"\"\"\n",
    "        result = handler.cleanup_expired()\n",
    "        \n",
    "        if result['deleted_count'] > 0:\n",
    "            return f\"ðŸ—‘ï¸ Deleted {result['deleted_count']} expired image(s).\"\n",
    "        else:\n",
    "            return \"âœ… No expired images to clean up.\"\n",
    "    \n",
    "    # Privacy policy text\n",
    "    privacy_text = \"\"\"\n",
    "## ðŸ“‹ Privacy & Data Policy\n",
    "\n",
    "Before uploading, please understand:\n",
    "\n",
    "- âœ… Images are analyzed by AI to extract design tokens\n",
    "- âœ… All images are **automatically deleted after 30 days**\n",
    "- âœ… EXIF metadata is stripped for privacy protection\n",
    "- âœ… Images are stored locally and never shared with third parties\n",
    "- âœ… Do not upload confidential client work without authorization\n",
    "- âœ… You retain all rights to your uploaded images\n",
    "\n",
    "**By checking the consent box, you agree to these terms.**\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create Gradio interface\n",
    "    with gr.Blocks(title=\"Tesserae - Moodboard Analyzer\", theme=gr.themes.Soft()) as demo:\n",
    "        \n",
    "        gr.Markdown(\"# ðŸŽ¨ Tesserae - AI Design Token Generator\")\n",
    "        gr.Markdown(\"*Upload moodboard images to extract design tokens automatically*\")\n",
    "        \n",
    "        with gr.Tab(\"Upload Moodboard\"):\n",
    "            \n",
    "            with gr.Row():\n",
    "                with gr.Column(scale=2):\n",
    "                    gr.Markdown(privacy_text)\n",
    "                    \n",
    "                    consent_checkbox = gr.Checkbox(\n",
    "                        label=\"I have read and agree to the privacy policy\",\n",
    "                        value=False\n",
    "                    )\n",
    "                    \n",
    "                    image_input = gr.Image(\n",
    "                        label=\"Upload Your Moodboard\",\n",
    "                        type=\"pil\",\n",
    "                        height=400\n",
    "                    )\n",
    "                    \n",
    "                    upload_btn = gr.Button(\"ðŸš€ Process Moodboard\", variant=\"primary\", size=\"lg\")\n",
    "                    \n",
    "                    status_output = gr.Textbox(\n",
    "                        label=\"Status\",\n",
    "                        placeholder=\"Upload an image to get started...\",\n",
    "                        interactive=False\n",
    "                    )\n",
    "                \n",
    "                with gr.Column(scale=2):\n",
    "                    gr.Markdown(\"### ðŸ“Š Processing Results\")\n",
    "                    \n",
    "                    processed_image = gr.Image(\n",
    "                        label=\"Processed Image (Metadata Stripped)\",\n",
    "                        type=\"pil\"\n",
    "                    )\n",
    "                    \n",
    "                    metadata_output = gr.Markdown(\"*Upload results will appear here*\")\n",
    "        \n",
    "        with gr.Tab(\"System Management\"):\n",
    "            gr.Markdown(\"## ðŸ”§ System Tools\")\n",
    "            gr.Markdown(\"Manage uploaded images and system cleanup\")\n",
    "            \n",
    "            cleanup_btn = gr.Button(\"ðŸ—‘ï¸ Clean Up Expired Images\", variant=\"secondary\")\n",
    "            cleanup_output = gr.Textbox(\n",
    "                label=\"Cleanup Status\",\n",
    "                interactive=False\n",
    "            )\n",
    "            \n",
    "            gr.Markdown(\"\"\"\n",
    "### ðŸ“ Notes:\n",
    "- Images are automatically deleted after 30 days\n",
    "- Run cleanup manually to free storage space immediately\n",
    "- All processing happens locally on your machine\n",
    "            \"\"\")\n",
    "        \n",
    "        with gr.Tab(\"About Tesserae\"):\n",
    "            gr.Markdown(\"\"\"\n",
    "## ðŸŽ¯ About This Tool\n",
    "\n",
    "**Tesserae** is an AI-powered design system generator that analyzes moodboard images and automatically extracts:\n",
    "\n",
    "- ðŸŽ¨ Color palettes with semantic naming\n",
    "- ðŸ“ Spacing and layout patterns  \n",
    "- ðŸ”¤ Typography recommendations\n",
    "- â™¿ Accessibility compliance checks\n",
    "\n",
    "### Current Development Status\n",
    "\n",
    "âœ… **Phase 1 Complete:** Image upload with privacy safeguards  \n",
    "ðŸ”„ **Phase 2 In Progress:** Color extraction algorithms  \n",
    "â³ **Phase 3 Planned:** Pattern recognition  \n",
    "â³ **Phase 4 Planned:** Token generation & export\n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "This project follows strict ethical guidelines:\n",
    "- Privacy-first design with automatic deletion\n",
    "- No training on user data without consent\n",
    "- Transparent AI decision-making\n",
    "- Human oversight at all critical points\n",
    "\n",
    "### Student Project Info\n",
    "\n",
    "**Creator:** Vivian Zhou  \n",
    "**Course:** Applied AI Design and Development Lab  \n",
    "**Instructor:** Dan Bartlett\n",
    "\n",
    "---\n",
    "\n",
    "*For questions or feedback about Tesserae, please contact through course channels.*\n",
    "            \"\"\")\n",
    "        \n",
    "        # Connect event handlers\n",
    "        upload_btn.click(\n",
    "            fn=process_moodboard,\n",
    "            inputs=[image_input, consent_checkbox],\n",
    "            outputs=[status_output, processed_image, metadata_output]\n",
    "        )\n",
    "        \n",
    "        cleanup_btn.click(\n",
    "            fn=check_expired_images,\n",
    "            outputs=cleanup_output\n",
    "        )\n",
    "    \n",
    "    return demo\n",
    "\n",
    "# Launch function for notebook\n",
    "def launch_tesserae_ui(share=True):\n",
    "    \"\"\"\n",
    "    Launch the Tesserae interface.\n",
    "    \n",
    "    Args:\n",
    "        share: If True, creates a public link (use for demos only)\n",
    "    \"\"\"\n",
    "    demo = create_tesserae_interface()\n",
    "    demo.launch(share=share, server_name=\"0.0.0.0\", server_port=7867)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c08e83a-d46e-47c9-bac6-ad15f1f9ba45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install packages needed for color extraction\n",
    "print(\"Installing color analysis packages...\")\n",
    "\n",
    "packages = [\n",
    "    \"scikit-learn\",        # K-means clustering for color extraction\n",
    "    \"colorthief\",          # Color analysis\n",
    "    \"webcolors\",           # Color name mapping\n",
    "]\n",
    "\n",
    "for pkg in packages:\n",
    "    print(f\"Installing {pkg}...\")\n",
    "    !pip install -q {pkg}\n",
    "\n",
    "print(\"âœ… Color extraction packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e35ab3-d3c4-4ae5-bdff-eb155202f021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix webcolors compatibility issue\n",
    "print(\"Installing compatible webcolors version...\")\n",
    "!pip install webcolors==1.11.1\n",
    "\n",
    "print(\"âœ… Installed webcolors 1.11.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4a8cac-1007-40ce-b090-e263b88192e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install OpenCV and scipy for pattern recognition\n",
    "print(\"Installing pattern recognition packages...\")\n",
    "\n",
    "!pip install opencv-python scipy\n",
    "\n",
    "print(\"âœ… Pattern recognition packages installed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18337202-4291-4a22-bc78-87fdc549862f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix OpenCV missing library issue\n",
    "print(\"Installing OpenCV headless version...\")\n",
    "\n",
    "# Uninstall regular opencv\n",
    "!pip uninstall opencv-python -y\n",
    "\n",
    "# Install headless version (works without display/GL libraries)\n",
    "!pip install opencv-python-headless\n",
    "\n",
    "print(\"âœ… Installed OpenCV headless version\")\n",
    "print(\"Now restart your kernel and try again!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "242030b2-e74c-415c-a68f-f2310283f50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic cell - CHECK THE FILE\n",
    "from pathlib import Path\n",
    "\n",
    "file_path = Path('tesserae_ui_final.py')\n",
    "\n",
    "if file_path.exists():\n",
    "    print(\"âœ… File exists\")\n",
    "    \n",
    "    # Read the file and check for the function\n",
    "    with open(file_path, 'r') as f:\n",
    "        content = f.read()\n",
    "    \n",
    "    if 'def launch_tesserae_ui' in content:\n",
    "        print(\"âœ… Function 'launch_tesserae_ui' found in file\")\n",
    "    else:\n",
    "        print(\"âŒ Function 'launch_tesserae_ui' NOT found in file\")\n",
    "        print(\"\\nSearching for what functions ARE defined...\")\n",
    "        lines = content.split('\\n')\n",
    "        for line in lines:\n",
    "            if line.strip().startswith('def ') and '(' in line:\n",
    "                print(f\"  Found: {line.strip()}\")\n",
    "    \n",
    "    # Check for syntax errors\n",
    "    try:\n",
    "        compile(content, 'tesserae_ui_final.py', 'exec')\n",
    "        print(\"âœ… No syntax errors detected\")\n",
    "    except SyntaxError as e:\n",
    "        print(f\"âŒ Syntax error: {e}\")\n",
    "        print(f\"   Line {e.lineno}: {e.text}\")\n",
    "else:\n",
    "    print(\"âŒ File 'tesserae_ui_final.py' does not exist\")\n",
    "    print(\"\\nAvailable .py files:\")\n",
    "    for f in Path('.').glob('*.py'):\n",
    "        print(f\"  â€¢ {f.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8223e46-52b2-4e9b-ac21-51c513201d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinstall opencv-python-headless to make sure it's available\n",
    "print(\"Ensuring OpenCV headless is installed...\")\n",
    "\n",
    "!pip uninstall opencv-python opencv-python-headless -y\n",
    "!pip install opencv-python-headless\n",
    "\n",
    "print(\"âœ… OpenCV headless installed\")\n",
    "print(\"\\nâš ï¸  IMPORTANT: Now restart your kernel!\")\n",
    "print(\"   Kernel â†’ Restart Kernel\")\n",
    "print(\"   Then re-run your import cells\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7768b1-915c-46d9-b1f2-cd674a62aa5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tesserae_ui_final import launch_tesserae_ui\n",
    "\n",
    "launch_tesserae_ui(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
